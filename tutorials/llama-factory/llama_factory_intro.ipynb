{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "241b4767-584b-4aa8-8a7b-af8dc45583be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T09:21:08.908360Z",
     "iopub.status.busy": "2024-12-01T09:21:08.907650Z",
     "iopub.status.idle": "2024-12-01T09:21:08.914088Z",
     "shell.execute_reply": "2024-12-01T09:21:08.912868Z",
     "shell.execute_reply.started": "2024-12-01T09:21:08.908318Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install llmtuner\n",
    "# !git clone https://github.com/hiyouga/LLaMA-Factory.git\n",
    "# %cd LLaMA-Factory\n",
    "# !pip install \"unsloth @ git+https://github.com/unslothai/unsloth.git\"\n",
    "# %pwd\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "495c5a4a-6269-431c-bc47-da50ffc4918b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T09:21:08.916348Z",
     "iopub.status.busy": "2024-12-01T09:21:08.915891Z",
     "iopub.status.idle": "2024-12-01T09:21:09.043131Z",
     "shell.execute_reply": "2024-12-01T09:21:09.041306Z",
     "shell.execute_reply.started": "2024-12-01T09:21:08.916309Z"
    }
   },
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240fa421-93d7-4d45-a8f3-c8eeba123097",
   "metadata": {},
   "source": [
    "- https://llamafactory.readthedocs.io/zh-cn/latest/index.html\n",
    "    - `conda activate lf`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6a83bd-fcb9-4041-b5f1-a699a12398c3",
   "metadata": {},
   "source": [
    "### 安装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bd91c2-af5b-42bd-aa45-35dcd412c80c",
   "metadata": {},
   "source": [
    "- 安装验证\n",
    "  \n",
    "```\n",
    "llamafactory-cli version\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7c7cf5-0460-4624-8b5a-b921fa9b1baf",
   "metadata": {},
   "source": [
    "### 项目结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252ddfc4-8e3c-4742-8f3f-5f68141f9168",
   "metadata": {},
   "source": [
    "- 支持的模型\n",
    "    - https://github.com/hiyouga/LLaMA-Factory/blob/main/src/llamafactory/extras/constants.py\n",
    "- 支持的 template\n",
    "    - https://github.com/hiyouga/LLaMA-Factory/blob/main/src/llamafactory/data/template.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e2df64-0f28-49f7-b9bd-546b93a21635",
   "metadata": {},
   "source": [
    "### train webui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dc350f-5db2-4c48-8868-7ff7a4b59440",
   "metadata": {},
   "source": [
    "- `llamafactory-cli webui`\n",
    "    - `export GRADIO_SHARE=1`\n",
    "    - `CUDA_VISIBLE_DEVICES=0 GRADIO_SHARE=1 GRADIO_SERVER_PORT=7860 llamafactory-cli webui`\n",
    "        - `CUDA_VISIBLE_DEVICES=0,1 GRADIO_SHARE=1 ...`：多卡；\n",
    "- 代理 proxy 与 graido localhost 的问题(此设置会使 localhost 和 127.0.0.1 的请求直接通过，而不会经过代理。)\n",
    "    ```\n",
    "    export no_proxy=\"localhost,127.0.0.1\"\n",
    "    export HTTP_PROXY='http://127.0.0.1:7890'\n",
    "    export HTTPS_PROXY='http://127.0.0.1:7890'\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a5e73f0-6ea4-47f1-a661-7c4ec2c06aac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T09:21:33.877987Z",
     "iopub.status.busy": "2024-12-01T09:21:33.877338Z",
     "iopub.status.idle": "2024-12-01T09:21:33.894153Z",
     "shell.execute_reply": "2024-12-01T09:21:33.891780Z",
     "shell.execute_reply.started": "2024-12-01T09:21:33.877940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/whaow/workspaces/llms_tuning/tutorials/llama-factory/LLaMA-Factory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/whaow/workspaces/llms_tuning/tutorials/llama-factory/LLaMA-Factory'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd LLaMA-Factory\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80cec702-6c0a-4ec9-bec4-9f052bf79155",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T09:31:45.020214Z",
     "iopub.status.busy": "2024-12-01T09:31:45.019572Z",
     "iopub.status.idle": "2024-12-01T09:31:45.028509Z",
     "shell.execute_reply": "2024-12-01T09:31:45.026480Z",
     "shell.execute_reply.started": "2024-12-01T09:31:45.020166Z"
    }
   },
   "outputs": [],
   "source": [
    "# !python src/webui.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24b50e2-636a-444f-8869-0865260d99ac",
   "metadata": {},
   "source": [
    "### ui 关键配置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9273bd14-be78-430f-9889-f9043d8bfb58",
   "metadata": {},
   "source": [
    "- finetuning method\n",
    "    - full\n",
    "    - freeze：冻结部分模型参数（通常是底层参数，例如嵌入层和大部分 Transformer 层），仅训练部分参数（通常是任务相关的上层参数，如输出层）。\n",
    "    - lora\n",
    "- lora\n",
    "    - rank：8\n",
    "    - alpha：16（Lora scaling coefficient.，缩放系数）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7390968-9cc5-4016-b23a-6e3177b7bae3",
   "metadata": {},
   "source": [
    "### pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22420dca-dcd6-4335-9579-d33369e97465",
   "metadata": {},
   "source": [
    "- (lora)训练\n",
    "    - 评估\n",
    "        - 加载训练后的 checkpoints，chat 中直观验证\n",
    "- (merge)合并\n",
    "- 推理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48af92b5-461f-4024-ab9e-8ab44991d494",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4ffda0-a692-43c2-a240-ed0538365e53",
   "metadata": {},
   "source": [
    "- alpaca-style\n",
    "    - instruct\n",
    "    - input\n",
    "    - output\n",
    "\n",
    "```\n",
    "{\n",
    "  \"instruction\": \"Rewrite the following sentence using passive voice.\",\n",
    "  \"input\": \"The team achieved great results.\",\n",
    "  \"output\": \"Great results were achieved by the team.\"\n",
    "}\n",
    "\n",
    "\n",
    "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Rewrite the following sentence using passive voice.\n",
    "\n",
    "### Input:\n",
    "The team achieved great results.\n",
    "\n",
    "### Response:\n",
    "Great results were achieved by the team.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85e9154-dc6b-4ce0-a4fb-b346d5e4eb0f",
   "metadata": {},
   "source": [
    "### misc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c7c1d5-347a-4933-9d69-4a9fe61241f9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "- data\n",
    "    - `dataset_info.json`: https://github.com/hiyouga/LLaMA-Factory/blob/main/data/dataset_info.json\n",
    "        - identity.json\n",
    "        - 自定义数据都要配置进这个 json 文件中，webui 才可识别；\n",
    "        - 预览（preview）的话：需要是 datasset_info.json 配置的本地文件，而不能是 hf 远端的文件（`hf_hub_url`）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
