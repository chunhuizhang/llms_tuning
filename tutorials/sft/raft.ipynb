{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6dd8dc7-d516-4d05-be43-b36d30bea919",
   "metadata": {},
   "source": [
    "- 数据构建：training data\n",
    "    - `{Q,D,A}`: query, documents, answer\n",
    "    - RAFT 为每个查询创建了两种不同的训练样本：\n",
    "        - Core documents\n",
    "        - Tangent documents\n",
    "    - 场景一：混合文档集 {C, T}\n",
    "        - 目的：教会模型从一堆良莠不齐的文档中识别并提取出有用的信息，同时忽略无关的干扰信息。\n",
    "        - 实现：将核心文档和干扰文档混合在一起，作为输入提供给模型。\n",
    "    - 场景二：纯干扰文档集 {T}\n",
    "        - 目的：教会模型在所有提供的信息都无用的情况下，不要强行回答（即不要产生幻觉）。此时，模型应该学会依赖其内部知识，或者直接表明“我不知道”。\n",
    "        - 实现：只提供干扰文档给模型。\n",
    "-  使用“思维链 (Chain-of-Thought, CoT)”生成答案\n",
    "    -  在生成答案（A）时，RAFT 采用思维链 (CoT) 推理。这意味着答案不仅包含最终结果，还包含一个详细的、分步骤的推理过程。\n",
    "        -  目的：让模型的回答过程更加透明和可追溯。模型被训练成需要引用它所使用的文档中的具体段落来支持它的结论。\n",
    "        -  示例：“根据文档A的第三段所述...，再结合文档B的第一段...，可以得出结论...。”\n",
    "-  通过上述精巧的训练过程，RAFT 实现了多个关键优势：\n",
    "    -  提高准确性 (Accuracy↑)：通过训练，模型学会了专注于核心信息，从而在专业领域的问答上更准确。\n",
    "    -  减少幻觉 (Hallucinations↓)：当面对一堆无关信息时，模型被训练成倾向于拒绝回答或依赖内部知识，而不是胡编乱造。\n",
    "    -  减少过拟合 (Overfitting↓)：模型学习的是一种“引用和推理”的通用能力，而不是死记硬背特定的问答对。\n",
    "    -  提高透明度 (Transparency↑)：思维链和引用机制让用户可以清楚地看到答案的来源和推理路径。\n",
    "    -  可扩展性与鲁棒性 (Scalable & Robust↑)：这个框架可以灵活地应用于不同的模型和数据集，非常适合需要高可靠性的企业级应用。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
