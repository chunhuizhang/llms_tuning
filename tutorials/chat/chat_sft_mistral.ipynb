{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8669a35-7487-491c-a500-35ca23267c6e",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/Mistral/Supervised_fine_tuning_(SFT)_of_an_LLM_using_Hugging_Face_tooling.ipynb#scrollTo=IQ1sMda27Zj6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7b0efcb-9a23-4173-91db-d39e9aff0498",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T03:36:53.952452Z",
     "iopub.status.busy": "2024-08-31T03:36:53.952141Z",
     "iopub.status.idle": "2024-08-31T03:36:53.958796Z",
     "shell.execute_reply": "2024-08-31T03:36:53.957799Z",
     "shell.execute_reply.started": "2024-08-31T03:36:53.952431Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7890'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81e7377-8f00-47c4-a2ef-cfcc39187a02",
   "metadata": {},
   "source": [
    "### about SFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c74e257-5ea3-4f9b-83b2-ec12cfcacced",
   "metadata": {},
   "source": [
    "Recall that creating a ChatGPT at home involves 3 steps:\n",
    "\n",
    "1. pre-training a large language model (LLM) to predict the next token on internet-scale data, on clusters of thousands of GPUs. One calls the result a \"base model\"\n",
    "2. supervised fine-tuning (SFT) to turn the base model into a useful assistant\n",
    "   - base model => \"chatbot\"/\"assistant\"\n",
    "   - fine-tuning the model on human instruction data, using the cross-entropy loss.\n",
    "   - This means that the model is **still trained to predict the next token**, although we now want the model to generate useful completions given an instruction like \"what are 10 things to do in London?\", \"How can I make pancakes?\" or \"Write me a poem about elephants\".\n",
    "   - https://gizmodo.com/chatgpt-openai-ai-contractors-15-dollars-per-hour-1850415474\n",
    "       - 工人通常每小时赚15美元的标注合同工\n",
    "4. human preference fine-tuning which increases the assistant's friendliness, helpfulness and safety."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ef4bb2-54ac-4028-b56a-8f6eeeea8472",
   "metadata": {},
   "source": [
    "SFT\n",
    "- RAG SFT\n",
    "    - https://www.bilibili.com/video/BV1Yx4y147t4/\n",
    "- Multi-Turn conversation SFT\n",
    "- Tool use (function calling) SFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd78fbf3-6e3d-4875-bb27-6b5b359e9e63",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6a5d0d-867f-41fd-bc15-f0af9701d100",
   "metadata": {},
   "source": [
    "- Zephyr: distilled SFT （dSFT），distilled DPO（dDPO）\n",
    "    - https://arxiv.org/pdf/2310.16944\n",
    "    - https://github.com/huggingface/alignment-handbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45e0ee8f-945f-452f-aede-5553a22ea265",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T03:36:55.791807Z",
     "iopub.status.busy": "2024-08-31T03:36:55.791167Z",
     "iopub.status.idle": "2024-08-31T03:37:03.774785Z",
     "shell.execute_reply": "2024-08-31T03:37:03.773334Z",
     "shell.execute_reply.started": "2024-08-31T03:36:55.791760Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# based on config\n",
    "raw_datasets = load_dataset(\"HuggingFaceH4/ultrachat_200k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4acada79-94f3-4d54-b197-be0f843f5fc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T03:37:06.450356Z",
     "iopub.status.busy": "2024-08-31T03:37:06.449752Z",
     "iopub.status.idle": "2024-08-31T03:37:06.468913Z",
     "shell.execute_reply": "2024-08-31T03:37:06.466640Z",
     "shell.execute_reply.started": "2024-08-31T03:37:06.450314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train_sft: Dataset({\n",
       "        features: ['prompt', 'prompt_id', 'messages'],\n",
       "        num_rows: 207865\n",
       "    })\n",
       "    test_sft: Dataset({\n",
       "        features: ['prompt', 'prompt_id', 'messages'],\n",
       "        num_rows: 23110\n",
       "    })\n",
       "    train_gen: Dataset({\n",
       "        features: ['prompt', 'prompt_id', 'messages'],\n",
       "        num_rows: 256032\n",
       "    })\n",
       "    test_gen: Dataset({\n",
       "        features: ['prompt', 'prompt_id', 'messages'],\n",
       "        num_rows: 28304\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf93a4f5-3eb0-4bf0-9f18-a49e8e5d9212",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T03:37:13.631714Z",
     "iopub.status.busy": "2024-08-31T03:37:13.631054Z",
     "iopub.status.idle": "2024-08-31T03:37:13.658337Z",
     "shell.execute_reply": "2024-08-31T03:37:13.656215Z",
     "shell.execute_reply.started": "2024-08-31T03:37:13.631666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'prompt_id', 'messages'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['prompt', 'prompt_id', 'messages'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "# remove this when done debugging\n",
    "indices = range(0,100)\n",
    "\n",
    "dataset_dict = {\"train\": raw_datasets[\"train_sft\"].select(indices),\n",
    "                \"test\": raw_datasets[\"test_sft\"].select(indices)}\n",
    "\n",
    "raw_datasets = DatasetDict(dataset_dict)\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b005cc2c-25ad-43a6-a7f9-b3631f4b6f0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T03:38:08.203837Z",
     "iopub.status.busy": "2024-08-31T03:38:08.203189Z",
     "iopub.status.idle": "2024-08-31T03:38:08.216764Z",
     "shell.execute_reply": "2024-08-31T03:38:08.214584Z",
     "shell.execute_reply.started": "2024-08-31T03:38:08.203791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['prompt', 'prompt_id', 'messages'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e72cbc84-a158-44a9-8c67-15b83e08c7a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T03:40:44.981938Z",
     "iopub.status.busy": "2024-08-31T03:40:44.981253Z",
     "iopub.status.idle": "2024-08-31T03:40:44.993049Z",
     "shell.execute_reply": "2024-08-31T03:40:44.990854Z",
     "shell.execute_reply.started": "2024-08-31T03:40:44.981888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f0e37e9f7800261167ce91143f98f511f768847236f133f2d0aed60b444ebe57 These instructions apply to section-based themes (Responsive 6.0+, Retina 4.0+, Parallax 3.0+ Turbo 2.0+, Mobilia 5.0+). What theme version am I using?\n",
      "On your Collections pages & Featured Collections sections, you can easily show the secondary image of a product on hover by enabling one of the theme's built-in settings!\n",
      "Your Collection pages & Featured Collections sections will now display the secondary product image just by hovering over that product image thumbnail.\n",
      "Does this feature apply to all sections of the theme or just specific ones as listed in the text material?\n"
     ]
    }
   ],
   "source": [
    "print(raw_datasets['train'][0]['prompt_id'], raw_datasets['train'][0]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95daf2e2-a290-457d-b94d-5d52b141075c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T03:42:18.184856Z",
     "iopub.status.busy": "2024-08-31T03:42:18.184212Z",
     "iopub.status.idle": "2024-08-31T03:42:18.196683Z",
     "shell.execute_reply": "2024-08-31T03:42:18.194883Z",
     "shell.execute_reply.started": "2024-08-31T03:42:18.184809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user                :  These instructions apply to section-based themes (Responsive 6.0+, Retina 4.0+, Parallax 3.0+ Turbo 2.0+, Mobilia 5.0+). What theme version am I using?\n",
      "On your Collections pages & Featured Collections sections, you can easily show the secondary image of a product on hover by enabling one of the theme's built-in settings!\n",
      "Your Collection pages & Featured Collections sections will now display the secondary product image just by hovering over that product image thumbnail.\n",
      "Does this feature apply to all sections of the theme or just specific ones as listed in the text material?\n",
      "assistant           :  This feature only applies to Collection pages and Featured Collections sections of the section-based themes listed in the text material.\n",
      "user                :  Can you guide me through the process of enabling the secondary image hover feature on my Collection pages and Featured Collections sections?\n",
      "assistant           :  Sure, here are the steps to enable the secondary image hover feature on your Collection pages and Featured Collections sections:\n",
      "\n",
      "1. Log in to your Shopify account and go to your Online Store.\n",
      "2. Click on Customize theme for the section-based theme you are using.\n",
      "3. Navigate to the Collection pages or Featured Collections section where you want to enable the secondary image hover feature.\n",
      "4. With the section open, click on the section's setting (gear) icon in the top-left corner.\n",
      "5. In the settings panel that appears, look for an option labeled 'Image display' or 'Image hover'.\n",
      "6. If available, select 'Show secondary image on hover'.\n",
      "7. Save the changes and preview the Collection/Featured Collection page to see the effect.\n",
      "\n",
      "If you're having trouble finding the setting, the best thing to do is refer to your theme's documentation, since the location and labeling of settings can vary between themes.\n",
      "user                :  Can you provide me with a link to the documentation for my theme?\n",
      "assistant           :  I don't have access to your store's theme information. However, you can usually find the documentation for your theme by going to the shopify theme store, finding your theme and clicking on the 'support' link located in the bottom right corner of the page. Alternatively, you can do a google search for the name of your theme followed by 'documentation' or 'user guide'.\n",
      "user                :  Can you confirm if this feature also works for the Quick Shop section of my theme?\n",
      "assistant           :  The secondary image hover feature may or may not work for your Quick Shop section, depending on the configuration of your theme. Some themes include this feature in the Quick Shop section by default, while others may require additional customization. To check if this feature is available for the Quick Shop section of your theme, follow these steps:\n",
      "\n",
      "1. Go to the Quick Shop section where you would like to enable the feature. 2. Click on the Quick Shop settings icon (gear icon) and look for 'Image display' or 'Image hover'. 3. If available, select 'Show secondary image on hover'. 4. Save the changes. If this option is not available in your Quick Shop section settings, you may need to reach out to your theme developer for assistance with customizing your Quick Shop section to include this feature.\n"
     ]
    }
   ],
   "source": [
    "for msg in raw_datasets['train'][0]['messages']:\n",
    "    role = msg['role']\n",
    "    content = msg['content']\n",
    "    print(f'{role:20}:  {content}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41757a0-acf7-46d4-9123-330f335248a5",
   "metadata": {},
   "source": [
    "### tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d7051b-7b56-4694-9ee4-e9a0de9d790f",
   "metadata": {},
   "source": [
    "- pad token\n",
    "    - During pre-training, one doesn't need to pad since one just creates blocks of text to predict the next token, but during fine-tuning, we will need to pad the (instruction, completion) pairs in order to create batches of equal length.\n",
    "- max seqlen\n",
    "    - this is required in order to truncate sequences which are too long for the model. Here we decide to train on at most 2048 tokens.\n",
    "- chat template：https://huggingface.co/blog/chat-templates\n",
    "    - `<|user|>` to indicate a user message and `<|assistant|>` to indicate the chatbot's response\n",
    "    - 在 hf Transformers，chat_template 定义在 tokenizer\n",
    "    - base model 是 None，instruct model 对应的 tokenizer 会有定义；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19c71379-030f-4aa5-b84f-7f58c75b5b36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T03:44:15.001619Z",
     "iopub.status.busy": "2024-08-31T03:44:15.001289Z",
     "iopub.status.idle": "2024-08-31T03:44:15.009034Z",
     "shell.execute_reply": "2024-08-31T03:44:15.007072Z",
     "shell.execute_reply.started": "2024-08-31T03:44:15.001597Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59fc93d5-fd87-401d-8c15-1cd2968c3f15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T03:44:16.729119Z",
     "iopub.status.busy": "2024-08-31T03:44:16.728482Z",
     "iopub.status.idle": "2024-08-31T03:44:17.117782Z",
     "shell.execute_reply": "2024-08-31T03:44:17.115639Z",
     "shell.execute_reply.started": "2024-08-31T03:44:16.729075Z"
    }
   },
   "outputs": [],
   "source": [
    "model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfb92f40-5d1f-4aa7-ba39-60c1cb552f12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T03:46:32.996905Z",
     "iopub.status.busy": "2024-08-31T03:46:32.996252Z",
     "iopub.status.idle": "2024-08-31T03:46:33.008761Z",
     "shell.execute_reply": "2024-08-31T03:46:33.006603Z",
     "shell.execute_reply.started": "2024-08-31T03:46:32.996859Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token, tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d28e294b-fd87-496e-a5bc-0858591e1955",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T04:11:36.683420Z",
     "iopub.status.busy": "2024-08-31T04:11:36.682775Z",
     "iopub.status.idle": "2024-08-31T04:11:36.696004Z",
     "shell.execute_reply": "2024-08-31T04:11:36.693651Z",
     "shell.execute_reply.started": "2024-08-31T04:11:36.683372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> </s>\n",
      "[1] [2]\n",
      "<s> </s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.bos_token, tokenizer.eos_token)\n",
    "print(tokenizer.encode('<s>', add_special_tokens=False), tokenizer.encode('</s>', add_special_tokens=False))\n",
    "print(tokenizer.decode(1), tokenizer.decode(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf6f70e7-a27d-4951-8314-15f392f8b156",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T04:13:43.830587Z",
     "iopub.status.busy": "2024-08-31T04:13:43.829925Z",
     "iopub.status.idle": "2024-08-31T04:13:43.842191Z",
     "shell.execute_reply": "2024-08-31T04:13:43.840045Z",
     "shell.execute_reply.started": "2024-08-31T04:13:43.830540Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000000000000019884624838656"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed19b691-ddb5-4657-a172-a5e83a4f6882",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T04:13:54.477226Z",
     "iopub.status.busy": "2024-08-31T04:13:54.476576Z",
     "iopub.status.idle": "2024-08-31T04:13:54.486150Z",
     "shell.execute_reply": "2024-08-31T04:13:54.483869Z",
     "shell.execute_reply.started": "2024-08-31T04:13:54.477179Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set reasonable default for models without max length\n",
    "if tokenizer.model_max_length > 100_000:\n",
    "  tokenizer.model_max_length = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f33ae93-fc02-46c8-811f-9624db99db29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T03:48:46.897756Z",
     "iopub.status.busy": "2024-08-31T03:48:46.897059Z",
     "iopub.status.idle": "2024-08-31T03:48:46.906835Z",
     "shell.execute_reply": "2024-08-31T03:48:46.904425Z",
     "shell.execute_reply.started": "2024-08-31T03:48:46.897664Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69592cff-50be-4e44-85ec-ba5f52a74baa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T04:04:53.721013Z",
     "iopub.status.busy": "2024-08-31T04:04:53.720688Z",
     "iopub.status.idle": "2024-08-31T04:04:55.631466Z",
     "shell.execute_reply": "2024-08-31T04:04:55.630146Z",
     "shell.execute_reply.started": "2024-08-31T04:04:53.720992Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/Meta-Llama-3-8B\n",
      "None\n",
      "======================\n",
      "meta-llama/Meta-Llama-3-8B-Instruct\n",
      "{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
      "\n",
      "'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "' }}{% endif %}\n",
      "======================\n",
      "mistralai/Mistral-7B-Instruct-v0.1\n",
      "{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token + ' ' }}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\n"
     ]
    }
   ],
   "source": [
    "print('meta-llama/Meta-Llama-3-8B')\n",
    "print(AutoTokenizer.from_pretrained('meta-llama/Meta-Llama-3-8B').chat_template)\n",
    "print('======================')\n",
    "print('meta-llama/Meta-Llama-3-8B-Instruct')\n",
    "print(AutoTokenizer.from_pretrained('meta-llama/Meta-Llama-3-8B-Instruct').chat_template)\n",
    "print('======================')\n",
    "print('mistralai/Mistral-7B-Instruct-v0.1')\n",
    "print(AutoTokenizer.from_pretrained('mistralai/Mistral-7B-Instruct-v0.1').chat_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db330362-1468-42e9-8043-fb32c98a30c9",
   "metadata": {},
   "source": [
    "### apply chat template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "04b02adf-a148-4b26-af34-cd4d549cb377",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T04:14:45.805975Z",
     "iopub.status.busy": "2024-08-31T04:14:45.805283Z",
     "iopub.status.idle": "2024-08-31T04:14:45.815901Z",
     "shell.execute_reply": "2024-08-31T04:14:45.813619Z",
     "shell.execute_reply.started": "2024-08-31T04:14:45.805927Z"
    }
   },
   "outputs": [],
   "source": [
    "DEFAULT_CHAT_TEMPLATE = \"{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ '<|user|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'system' %}\\n{{ '<|system|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '<|assistant|>\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '<|assistant|>' }}\\n{% endif %}\\n{% endfor %}\"\n",
    "tokenizer.chat_template = DEFAULT_CHAT_TEMPLATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e3904e-c24a-4dec-9601-35774f226fda",
   "metadata": {},
   "source": [
    "- `tokenizer.apply_chat_template(messages, tokenize=False)`\n",
    "    - 接受的是 list\n",
    "    - 基于 role\n",
    "        - `'<|user|>\\n' + message['content'] + eos_token`\n",
    "        - `'<|system|>\\n' + message['content'] + eos_token`\n",
    "        - `'<|assistant|>\\n'  + message['content'] + eos_token`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5d784368-67f0-4579-8bf7-440536c15f0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T04:20:23.305862Z",
     "iopub.status.busy": "2024-08-31T04:20:23.305171Z",
     "iopub.status.idle": "2024-08-31T04:20:23.316832Z",
     "shell.execute_reply": "2024-08-31T04:20:23.315190Z",
     "shell.execute_reply.started": "2024-08-31T04:20:23.305813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a16af539-8009-4274-bf4d-e36474818f9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T04:16:44.270884Z",
     "iopub.status.busy": "2024-08-31T04:16:44.270185Z",
     "iopub.status.idle": "2024-08-31T04:16:44.286822Z",
     "shell.execute_reply": "2024-08-31T04:16:44.284795Z",
     "shell.execute_reply.started": "2024-08-31T04:16:44.270834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prompt', 'prompt_id', 'messages']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "def apply_chat_template(example, tokenizer):\n",
    "    messages = example[\"messages\"]\n",
    "    # We add an empty system message if there is none\n",
    "    if messages[0][\"role\"] != \"system\":\n",
    "        messages.insert(0, {\"role\": \"system\", \"content\": \"\"})\n",
    "    example[\"text\"] = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "    return example\n",
    "\n",
    "column_names = list(raw_datasets[\"train\"].features)\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "454265d1-cdb9-46ac-b6c3-c2e1e2324e10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T04:16:49.687109Z",
     "iopub.status.busy": "2024-08-31T04:16:49.686454Z",
     "iopub.status.idle": "2024-08-31T04:16:58.434416Z",
     "shell.execute_reply": "2024-08-31T04:16:58.432998Z",
     "shell.execute_reply.started": "2024-08-31T04:16:49.687062Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526718fd056546e883eec53de1759662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template (num_proc=64):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0ad250f98d445798cedf81566ee4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template (num_proc=64):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_datasets = raw_datasets.map(apply_chat_template,\n",
    "                                num_proc=cpu_count(),\n",
    "                                fn_kwargs={\"tokenizer\": tokenizer},\n",
    "                                remove_columns=column_names,\n",
    "                                desc=\"Applying chat template\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a67c0e5a-11e3-407d-a2f1-c4d60e77e636",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T04:17:10.510420Z",
     "iopub.status.busy": "2024-08-31T04:17:10.509719Z",
     "iopub.status.idle": "2024-08-31T04:17:10.523789Z",
     "shell.execute_reply": "2024-08-31T04:17:10.521604Z",
     "shell.execute_reply.started": "2024-08-31T04:17:10.510365Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the splits\n",
    "train_dataset = raw_datasets[\"train\"]\n",
    "eval_dataset = raw_datasets[\"test\"]\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4f2ba065-b159-4049-a905-9fbe1854c22b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T04:17:47.845728Z",
     "iopub.status.busy": "2024-08-31T04:17:47.845039Z",
     "iopub.status.idle": "2024-08-31T04:17:47.856365Z",
     "shell.execute_reply": "2024-08-31T04:17:47.854906Z",
     "shell.execute_reply.started": "2024-08-31T04:17:47.845642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "</s>\n",
      "<|user|>\n",
      "These instructions apply to section-based themes (Responsive 6.0+, Retina 4.0+, Parallax 3.0+ Turbo 2.0+, Mobilia 5.0+). What theme version am I using?\n",
      "On your Collections pages & Featured Collections sections, you can easily show the secondary image of a product on hover by enabling one of the theme's built-in settings!\n",
      "Your Collection pages & Featured Collections sections will now display the secondary product image just by hovering over that product image thumbnail.\n",
      "Does this feature apply to all sections of the theme or just specific ones as listed in the text material?</s>\n",
      "<|assistant|>\n",
      "This feature only applies to Collection pages and Featured Collections sections of the section-based themes listed in the text material.</s>\n",
      "<|user|>\n",
      "Can you guide me through the process of enabling the secondary image hover feature on my Collection pages and Featured Collections sections?</s>\n",
      "<|assistant|>\n",
      "Sure, here are the steps to enable the secondary image hover feature on your Collection pages and Featured Collections sections:\n",
      "\n",
      "1. Log in to your Shopify account and go to your Online Store.\n",
      "2. Click on Customize theme for the section-based theme you are using.\n",
      "3. Navigate to the Collection pages or Featured Collections section where you want to enable the secondary image hover feature.\n",
      "4. With the section open, click on the section's setting (gear) icon in the top-left corner.\n",
      "5. In the settings panel that appears, look for an option labeled 'Image display' or 'Image hover'.\n",
      "6. If available, select 'Show secondary image on hover'.\n",
      "7. Save the changes and preview the Collection/Featured Collection page to see the effect.\n",
      "\n",
      "If you're having trouble finding the setting, the best thing to do is refer to your theme's documentation, since the location and labeling of settings can vary between themes.</s>\n",
      "<|user|>\n",
      "Can you provide me with a link to the documentation for my theme?</s>\n",
      "<|assistant|>\n",
      "I don't have access to your store's theme information. However, you can usually find the documentation for your theme by going to the shopify theme store, finding your theme and clicking on the 'support' link located in the bottom right corner of the page. Alternatively, you can do a google search for the name of your theme followed by 'documentation' or 'user guide'.</s>\n",
      "<|user|>\n",
      "Can you confirm if this feature also works for the Quick Shop section of my theme?</s>\n",
      "<|assistant|>\n",
      "The secondary image hover feature may or may not work for your Quick Shop section, depending on the configuration of your theme. Some themes include this feature in the Quick Shop section by default, while others may require additional customization. To check if this feature is available for the Quick Shop section of your theme, follow these steps:\n",
      "\n",
      "1. Go to the Quick Shop section where you would like to enable the feature. 2. Click on the Quick Shop settings icon (gear icon) and look for 'Image display' or 'Image hover'. 3. If available, select 'Show secondary image on hover'. 4. Save the changes. If this option is not available in your Quick Shop section settings, you may need to reach out to your theme developer for assistance with customizing your Quick Shop section to include this feature.</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(raw_datasets['train'][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891edef5-051d-43a3-9fdc-1f6bc98010ff",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6359e8ee-dd5b-4fca-9edc-bccd7e0e4c9b",
   "metadata": {},
   "source": [
    "- Full fine-tuning\n",
    "    - we will simply update **all the weights** of the base model during fine-tuning\n",
    "        - full precision (float32)\n",
    "        - mixed precision (a combination of float32 and float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93575408-ee0d-470a-9a88-e6a660e38b32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
