{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0457db7b-83fc-49f6-8903-e1006dcd9aba",
   "metadata": {},
   "source": [
    "- finetune Llama3-8B instruct model pipeline\n",
    "    - peft LoRA & bitsandbytes quantization\n",
    "    - RAG financial (chat/QA/instruct) dataset\n",
    "    - Accelerate distributed\n",
    "- training arguments\n",
    "- evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4df3a1dd-4631-49a9-9927-2799bac2533a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:40:06.790980Z",
     "iopub.status.busy": "2024-08-04T04:40:06.790710Z",
     "iopub.status.idle": "2024-08-04T04:40:06.794248Z",
     "shell.execute_reply": "2024-08-04T04:40:06.793735Z",
     "shell.execute_reply.started": "2024-08-04T04:40:06.790963Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7890'\n",
    "from IPython.display import Image\n",
    "from textwrap import dedent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9838163-65ae-4ac3-a08c-82ea82e69f16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T15:26:33.537596Z",
     "iopub.status.busy": "2024-07-22T15:26:33.537285Z",
     "iopub.status.idle": "2024-07-22T15:26:33.547830Z",
     "shell.execute_reply": "2024-07-22T15:26:33.546091Z",
     "shell.execute_reply.started": "2024-07-22T15:26:33.537570Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade trl\n",
    "# !pip install --upgrade bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1bd26ad-c9e4-4198-8117-bc2640a84aab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:37:53.935659Z",
     "iopub.status.busy": "2024-08-04T04:37:53.935075Z",
     "iopub.status.idle": "2024-08-04T04:38:07.393406Z",
     "shell.execute_reply": "2024-08-04T04:38:07.392521Z",
     "shell.execute_reply.started": "2024-08-04T04:37:53.935614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-04 12:38:06,081] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from typing import Dict, List\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline,\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    TaskType,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from trl import DataCollatorForCompletionOnlyLM, SFTConfig, SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76e091e0-b0b3-49e9-ba3a-e9ef1dfef0c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:38:07.395031Z",
     "iopub.status.busy": "2024-08-04T04:38:07.394675Z",
     "iopub.status.idle": "2024-08-04T04:38:07.400493Z",
     "shell.execute_reply": "2024-08-04T04:38:07.399724Z",
     "shell.execute_reply.started": "2024-08-04T04:38:07.395015Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9229bb-a47a-432b-91f9-5c7077af987a",
   "metadata": {},
   "source": [
    "## overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc8f7e95-3a13-4d91-8b6b-cb3b7b4320c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:34:25.034695Z",
     "iopub.status.busy": "2024-08-04T03:34:25.034094Z",
     "iopub.status.idle": "2024-08-04T03:34:25.051336Z",
     "shell.execute_reply": "2024-08-04T03:34:25.049732Z",
     "shell.execute_reply.started": "2024-08-04T03:34:25.034651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.mlexpert.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fbanner.2336875a.png&w=3840&q=75\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://www.mlexpert.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fbanner.2336875a.png&w=3840&q=75', width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9a1b13-45ac-407a-a2ff-71df851f6361",
   "metadata": {},
   "source": [
    "## constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54e7d77a-635d-4a06-bd96-16537289417a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:38:09.732460Z",
     "iopub.status.busy": "2024-08-04T04:38:09.732241Z",
     "iopub.status.idle": "2024-08-04T04:38:09.738288Z",
     "shell.execute_reply": "2024-08-04T04:38:09.737077Z",
     "shell.execute_reply.started": "2024-08-04T04:38:09.732446Z"
    }
   },
   "outputs": [],
   "source": [
    "pad_token = \"<|pad|>\"\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "new_model = \"Llama-3-8B-Instruct-Finance-RAG\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613b39e2-8b4e-47fb-8f14-3f12d447e10b",
   "metadata": {},
   "source": [
    "## model & tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b270cc26-e26a-44d2-bd3c-2ffb15ca2b06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:34:35.505581Z",
     "iopub.status.busy": "2024-08-04T03:34:35.504560Z",
     "iopub.status.idle": "2024-08-04T03:34:35.514116Z",
     "shell.execute_reply": "2024-08-04T03:34:35.512785Z",
     "shell.execute_reply.started": "2024-08-04T03:34:35.505524Z"
    }
   },
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, \n",
    "    bnb_4bit_quant_type=\"nf4\", \n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1539aa8d-039a-4646-8c64-8325def3b6b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:34:39.494473Z",
     "iopub.status.busy": "2024-08-04T03:34:39.493095Z",
     "iopub.status.idle": "2024-08-04T03:34:40.572755Z",
     "shell.execute_reply": "2024-08-04T03:34:40.571555Z",
     "shell.execute_reply.started": "2024-08-04T03:34:39.494411Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f5a5df9-fd62-4ea9-aa49-5c7260c6bb81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:34:48.376127Z",
     "iopub.status.busy": "2024-08-04T03:34:48.375580Z",
     "iopub.status.idle": "2024-08-04T03:34:48.383096Z",
     "shell.execute_reply": "2024-08-04T03:34:48.381733Z",
     "shell.execute_reply.started": "2024-08-04T03:34:48.376088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
      "\n",
      "'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "' }}{% endif %}\n"
     ]
    }
   ],
   "source": [
    "# 不是所有model的tokenizer都支持 chat_template\n",
    "print(tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6155989-ec2e-42c6-9aa5-be379f790dbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:35:03.702618Z",
     "iopub.status.busy": "2024-08-04T03:35:03.702024Z",
     "iopub.status.idle": "2024-08-04T03:35:04.415804Z",
     "shell.execute_reply": "2024-08-04T03:35:04.415236Z",
     "shell.execute_reply.started": "2024-08-04T03:35:03.702576Z"
    }
   },
   "outputs": [],
   "source": [
    "# 比如 base model\n",
    "AutoTokenizer.from_pretrained('meta-llama/Meta-Llama-3-8B', use_fast=True).chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0228da24-a453-42d2-9ff4-1fa573f9a5d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:35:18.286052Z",
     "iopub.status.busy": "2024-08-04T03:35:18.285654Z",
     "iopub.status.idle": "2024-08-04T03:35:18.291708Z",
     "shell.execute_reply": "2024-08-04T03:35:18.290885Z",
     "shell.execute_reply.started": "2024-08-04T03:35:18.286033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'bos_token': '<|begin_of_text|>', 'eos_token': '<|end_of_text|>'}, None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map, tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b83ef88-a801-4b3f-b7e7-5168104952b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:42:22.249382Z",
     "iopub.status.busy": "2024-08-04T03:42:22.247995Z",
     "iopub.status.idle": "2024-08-04T03:42:22.259283Z",
     "shell.execute_reply": "2024-08-04T03:42:22.257606Z",
     "shell.execute_reply.started": "2024-08-04T03:42:22.249304Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.add_special_tokens({\"pad_token\": pad_token})\n",
    "# training\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78b3fdef-51c2-431b-8cc6-ea5947a1e273",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:42:24.020788Z",
     "iopub.status.busy": "2024-08-04T03:42:24.020195Z",
     "iopub.status.idle": "2024-08-04T03:42:24.032835Z",
     "shell.execute_reply": "2024-08-04T03:42:24.030686Z",
     "shell.execute_reply.started": "2024-08-04T03:42:24.020744Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<|pad|>', 128256, '<|end_of_text|>', 128001)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tokenizer.pad_token, tokenizer.pad_token_id, tokenizer.eos_token, tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02428daa-e2cc-41d1-9195-677b06e4451e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:44:11.382558Z",
     "iopub.status.busy": "2024-08-04T03:44:11.382060Z",
     "iopub.status.idle": "2024-08-04T03:44:17.661804Z",
     "shell.execute_reply": "2024-08-04T03:44:17.660964Z",
     "shell.execute_reply.started": "2024-08-04T03:44:11.382536Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a2a19239bf44839082da6f2cbfa889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We've detected an older driver with an RTX 4000 series GPU. These drivers have issues with P2P. This can affect the multi-gpu inference when using accelerate device_map.Please make sure to update your driver to the latest version which resolves this.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=quantization_config,\n",
    "    #     attn_implementation=\"flash_attention_2\",\n",
    "    #     attn_implementation=\"sdpa\",\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffc7aea2-c662-4b8f-b060-22ae454650c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T15:26:51.557495Z",
     "iopub.status.busy": "2024-07-22T15:26:51.557315Z",
     "iopub.status.idle": "2024-07-22T15:26:51.563011Z",
     "shell.execute_reply": "2024-07-22T15:26:51.562219Z",
     "shell.execute_reply.started": "2024-07-22T15:26:51.557479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.added_tokens_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7aa0e0ed-b4ea-4d70-ac40-7887f73c6dae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:44:32.327512Z",
     "iopub.status.busy": "2024-08-04T03:44:32.326853Z",
     "iopub.status.idle": "2024-08-04T03:44:32.347448Z",
     "shell.execute_reply": "2024-08-04T03:44:32.346581Z",
     "shell.execute_reply.started": "2024-08-04T03:44:32.327475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Embedding(128256, 4096), 128000, 128257)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.embed_tokens, tokenizer.vocab_size, len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2914e036-7bee-4117-a1e6-b91dc5ac3f00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:44:57.322244Z",
     "iopub.status.busy": "2024-08-04T03:44:57.321762Z",
     "iopub.status.idle": "2024-08-04T03:44:57.378797Z",
     "shell.execute_reply": "2024-08-04T03:44:57.378011Z",
     "shell.execute_reply.started": "2024-08-04T03:44:57.322210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(128264, 4096)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d07a1a3d-3511-4403-98ac-71353be9d22f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:44:58.632262Z",
     "iopub.status.busy": "2024-08-04T03:44:58.631844Z",
     "iopub.status.idle": "2024-08-04T03:44:58.636932Z",
     "shell.execute_reply": "2024-08-04T03:44:58.636187Z",
     "shell.execute_reply.started": "2024-08-04T03:44:58.632240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16032.125, 16033.0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128257/8, 128264/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8573baa3-017a-4871-8898-7ab5e7b88334",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:45:00.467137Z",
     "iopub.status.busy": "2024-08-04T03:45:00.466727Z",
     "iopub.status.idle": "2024-08-04T03:45:00.472776Z",
     "shell.execute_reply": "2024-08-04T03:45:00.471987Z",
     "shell.execute_reply.started": "2024-08-04T03:45:00.467117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaConfig {\n",
       "  \"_name_or_path\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
       "  \"architectures\": [\n",
       "    \"LlamaForCausalLM\"\n",
       "  ],\n",
       "  \"attention_bias\": false,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 128000,\n",
       "  \"eos_token_id\": 128001,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 4096,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 14336,\n",
       "  \"max_position_embeddings\": 8192,\n",
       "  \"mlp_bias\": false,\n",
       "  \"model_type\": \"llama\",\n",
       "  \"num_attention_heads\": 32,\n",
       "  \"num_hidden_layers\": 32,\n",
       "  \"num_key_value_heads\": 8,\n",
       "  \"pretraining_tp\": 1,\n",
       "  \"quantization_config\": {\n",
       "    \"_load_in_4bit\": true,\n",
       "    \"_load_in_8bit\": false,\n",
       "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
       "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
       "    \"bnb_4bit_quant_type\": \"nf4\",\n",
       "    \"bnb_4bit_use_double_quant\": false,\n",
       "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
       "    \"llm_int8_has_fp16_weight\": false,\n",
       "    \"llm_int8_skip_modules\": null,\n",
       "    \"llm_int8_threshold\": 6.0,\n",
       "    \"load_in_4bit\": true,\n",
       "    \"load_in_8bit\": false,\n",
       "    \"quant_method\": \"bitsandbytes\"\n",
       "  },\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 500000.0,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.43.3\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 128264\n",
       "}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5028c28e-da27-4d22-901b-97d2a37a860a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:45:12.553636Z",
     "iopub.status.busy": "2024-08-04T03:45:12.553428Z",
     "iopub.status.idle": "2024-08-04T03:45:12.558504Z",
     "shell.execute_reply": "2024-08-04T03:45:12.557691Z",
     "shell.execute_reply.started": "2024-08-04T03:45:12.553622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|> 128000\n",
      "<|end_of_text|> 128001\n",
      "<|pad|> 128256\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.bos_token, tokenizer.bos_token_id)\n",
    "print(tokenizer.eos_token, tokenizer.eos_token_id)\n",
    "print(tokenizer.pad_token, tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdb2679-ed71-490d-95cb-7d5e9555064c",
   "metadata": {},
   "source": [
    "## dataset (数据集就代表着任务)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31622a9-f2fd-448a-a084-93042b1866e5",
   "metadata": {},
   "source": [
    "- RAG dataset with QA and context;\n",
    "    - Question + context => user query;\n",
    "    - Answer => assistant response;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3e41b83-f3cb-4c09-8d69-9e79b63a55c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:45:16.580292Z",
     "iopub.status.busy": "2024-08-04T03:45:16.579914Z",
     "iopub.status.idle": "2024-08-04T03:45:22.988595Z",
     "shell.execute_reply": "2024-08-04T03:45:22.987756Z",
     "shell.execute_reply.started": "2024-08-04T03:45:16.580274Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"virattt/financial-qa-10K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7859555-ba34-4929-8743-6f417ecdfe6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:45:50.698202Z",
     "iopub.status.busy": "2024-08-04T03:45:50.697936Z",
     "iopub.status.idle": "2024-08-04T03:45:50.703311Z",
     "shell.execute_reply": "2024-08-04T03:45:50.702566Z",
     "shell.execute_reply.started": "2024-08-04T03:45:50.698186Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'context', 'ticker', 'filing'],\n",
       "        num_rows: 7000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69c9be43-716d-4f89-876e-6aa6da6d3638",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:46:56.802491Z",
     "iopub.status.busy": "2024-08-04T03:46:56.801208Z",
     "iopub.status.idle": "2024-08-04T03:46:56.809214Z",
     "shell.execute_reply": "2024-08-04T03:46:56.808359Z",
     "shell.execute_reply.started": "2024-08-04T03:46:56.802444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': ['What area did NVIDIA initially focus on before expanding to other computationally intensive fields?'],\n",
       " 'answer': ['NVIDIA initially focused on PC graphics.'],\n",
       " 'context': ['Since our original focus on PC graphics, we have expanded to several other large and important computationally intensive fields.'],\n",
       " 'ticker': ['NVDA'],\n",
       " 'filing': ['2023_10K']}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a29c6862-fdf7-4112-876c-a533035fe98d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:47:45.968904Z",
     "iopub.status.busy": "2024-08-04T03:47:45.968039Z",
     "iopub.status.idle": "2024-08-04T03:47:45.978421Z",
     "shell.execute_reply": "2024-08-04T03:47:45.976909Z",
     "shell.execute_reply.started": "2024-08-04T03:47:45.968849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['question', 'answer', 'context', 'ticker', 'filing']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56291769-66b2-48e2-9ea3-60fbdb71cd0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:47:10.213485Z",
     "iopub.status.busy": "2024-08-04T03:47:10.213273Z",
     "iopub.status.idle": "2024-08-04T03:47:10.747136Z",
     "shell.execute_reply": "2024-08-04T03:47:10.745414Z",
     "shell.execute_reply.started": "2024-08-04T03:47:10.213472Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efbcffb82ef348df810fa4d9403c4955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/7000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whaow/anaconda3/lib/python3.10/site-packages/datasets/table.py:1392: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'context'],\n",
       "        num_rows: 7000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process(row):\n",
    "    return {\n",
    "        \"question\": row[\"question\"],\n",
    "        \"context\": row[\"context\"],\n",
    "        \"answer\": row[\"answer\"]\n",
    "    }\n",
    "new_dataset = dataset.map(process, num_proc=8, \n",
    "                          remove_columns=dataset[\"train\"].column_names)\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d267eb99-2041-4cea-bd9d-3e55219aff12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:48:06.884995Z",
     "iopub.status.busy": "2024-08-04T03:48:06.883617Z",
     "iopub.status.idle": "2024-08-04T03:48:06.928957Z",
     "shell.execute_reply": "2024-08-04T03:48:06.927677Z",
     "shell.execute_reply.started": "2024-08-04T03:48:06.884950Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What area did NVIDIA initially focus on before...</td>\n",
       "      <td>NVIDIA initially focused on PC graphics.</td>\n",
       "      <td>Since our original focus on PC graphics, we ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are some of the recent applications of GP...</td>\n",
       "      <td>Recent applications of GPU-powered deep learni...</td>\n",
       "      <td>Some of the most recent applications of GPU-po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What significant invention did NVIDIA create i...</td>\n",
       "      <td>NVIDIA invented the GPU in 1999.</td>\n",
       "      <td>Our invention of the GPU in 1999 defined moder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does NVIDIA's platform strategy contribute...</td>\n",
       "      <td>NVIDIA's platform strategy brings together har...</td>\n",
       "      <td>NVIDIA has a platform strategy, bringing toget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What does NVIDIA's CUDA programming model enable?</td>\n",
       "      <td>NVIDIA's CUDA programming model opened the par...</td>\n",
       "      <td>With our introduction of the CUDA programming ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What area did NVIDIA initially focus on before...   \n",
       "1  What are some of the recent applications of GP...   \n",
       "2  What significant invention did NVIDIA create i...   \n",
       "3  How does NVIDIA's platform strategy contribute...   \n",
       "4  What does NVIDIA's CUDA programming model enable?   \n",
       "\n",
       "                                              answer  \\\n",
       "0           NVIDIA initially focused on PC graphics.   \n",
       "1  Recent applications of GPU-powered deep learni...   \n",
       "2                   NVIDIA invented the GPU in 1999.   \n",
       "3  NVIDIA's platform strategy brings together har...   \n",
       "4  NVIDIA's CUDA programming model opened the par...   \n",
       "\n",
       "                                             context  \n",
       "0  Since our original focus on PC graphics, we ha...  \n",
       "1  Some of the most recent applications of GPU-po...  \n",
       "2  Our invention of the GPU in 1999 defined moder...  \n",
       "3  NVIDIA has a platform strategy, bringing toget...  \n",
       "4  With our introduction of the CUDA programming ...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = new_dataset['train'].to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41510e61-34a3-4ec8-b7bc-4fc074ebbcfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:48:09.730436Z",
     "iopub.status.busy": "2024-08-04T03:48:09.729606Z",
     "iopub.status.idle": "2024-08-04T03:48:09.750948Z",
     "shell.execute_reply": "2024-08-04T03:48:09.749626Z",
     "shell.execute_reply.started": "2024-08-04T03:48:09.730390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question  answer  context\n",
       "False     False   False      7000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44ee50f-e226-4512-8b20-fc1ac3aad4d3",
   "metadata": {},
   "source": [
    "### to chat dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2404347b-103d-4ae6-b433-9c038a9598e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:48:23.576831Z",
     "iopub.status.busy": "2024-08-04T03:48:23.575692Z",
     "iopub.status.idle": "2024-08-04T03:48:23.586448Z",
     "shell.execute_reply": "2024-08-04T03:48:23.585190Z",
     "shell.execute_reply.started": "2024-08-04T03:48:23.576786Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question    What area did NVIDIA initially focus on before...\n",
       "answer               NVIDIA initially focused on PC graphics.\n",
       "context     Since our original focus on PC graphics, we ha...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = df.iloc[0]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "23028cfe-fda9-477c-8924-cdfb49857ea0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:48:37.736117Z",
     "iopub.status.busy": "2024-08-04T03:48:37.735302Z",
     "iopub.status.idle": "2024-08-04T03:48:37.744817Z",
     "shell.execute_reply": "2024-08-04T03:48:37.743209Z",
     "shell.execute_reply.started": "2024-08-04T03:48:37.736068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "What area did NVIDIA initially focus on before expanding to other computationally intensive fields?\n",
      "\n",
      "Information:\n",
      "\n",
      "```\n",
      "Since our original focus on PC graphics, we have expanded to several other large and important computationally intensive fields.\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dedent(\n",
    "    f\"\"\"\n",
    "{row[\"question\"]}\n",
    "\n",
    "Information:\n",
    "\n",
    "```\n",
    "{row[\"context\"]}\n",
    "```\n",
    "\"\"\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "097bb1d4-9ccc-4131-8018-b4a69d87bd95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:54:11.868318Z",
     "iopub.status.busy": "2024-08-04T03:54:11.867170Z",
     "iopub.status.idle": "2024-08-04T03:54:11.875212Z",
     "shell.execute_reply": "2024-08-04T03:54:11.874431Z",
     "shell.execute_reply.started": "2024-08-04T03:54:11.868255Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_example(row: dict):\n",
    "    prompt = dedent(\n",
    "        f\"\"\"\n",
    "    {row[\"question\"]}\n",
    "\n",
    "    Information:\n",
    "\n",
    "    ```\n",
    "    {row[\"context\"]}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Use only the information to answer the question\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": row[\"answer\"]},\n",
    "    ]\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd85944b-b296-4209-a6d6-34872782e52d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:54:15.201397Z",
     "iopub.status.busy": "2024-08-04T03:54:15.200948Z",
     "iopub.status.idle": "2024-08-04T03:54:15.657493Z",
     "shell.execute_reply": "2024-08-04T03:54:15.656614Z",
     "shell.execute_reply.started": "2024-08-04T03:54:15.201384Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"text\"] = df.apply(format_example, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8faea26-d4cc-4294-a70d-07a0ad52103d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:54:17.312013Z",
     "iopub.status.busy": "2024-08-04T03:54:17.311755Z",
     "iopub.status.idle": "2024-08-04T03:54:17.316734Z",
     "shell.execute_reply": "2024-08-04T03:54:17.315915Z",
     "shell.execute_reply.started": "2024-08-04T03:54:17.311997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What area did NVIDIA initially focus on before expanding to other computationally intensive fields?\n",
      "\n",
      "Information:\n",
      "\n",
      "```\n",
      "Since our original focus on PC graphics, we have expanded to several other large and important computationally intensive fields.\n",
      "```<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "NVIDIA initially focused on PC graphics.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6f1da6a-ede6-416c-ac0b-b155568efd1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:54:43.411468Z",
     "iopub.status.busy": "2024-08-04T03:54:43.410914Z",
     "iopub.status.idle": "2024-08-04T03:54:43.416078Z",
     "shell.execute_reply": "2024-08-04T03:54:43.415279Z",
     "shell.execute_reply.started": "2024-08-04T03:54:43.411428Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_tokens(row: Dict) -> int:\n",
    "    return len(\n",
    "        tokenizer(\n",
    "            row[\"text\"],\n",
    "            add_special_tokens=True,\n",
    "            return_attention_mask=False,\n",
    "        )[\"input_ids\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9edde096-b702-4b10-9ff0-c024213a16c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:54:44.753353Z",
     "iopub.status.busy": "2024-08-04T03:54:44.753091Z",
     "iopub.status.idle": "2024-08-04T03:54:46.735211Z",
     "shell.execute_reply": "2024-08-04T03:54:46.734078Z",
     "shell.execute_reply.started": "2024-08-04T03:54:44.753338Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"token_count\"] = df.apply(count_tokens, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9e9283f7-1246-4ca4-8c20-894cf775431a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:54:48.128133Z",
     "iopub.status.busy": "2024-08-04T03:54:48.127890Z",
     "iopub.status.idle": "2024-08-04T03:54:48.137514Z",
     "shell.execute_reply": "2024-08-04T03:54:48.136558Z",
     "shell.execute_reply.started": "2024-08-04T03:54:48.128119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>text</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What area did NVIDIA initially focus on before...</td>\n",
       "      <td>NVIDIA initially focused on PC graphics.</td>\n",
       "      <td>Since our original focus on PC graphics, we ha...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are some of the recent applications of GP...</td>\n",
       "      <td>Recent applications of GPU-powered deep learni...</td>\n",
       "      <td>Some of the most recent applications of GPU-po...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What significant invention did NVIDIA create i...</td>\n",
       "      <td>NVIDIA invented the GPU in 1999.</td>\n",
       "      <td>Our invention of the GPU in 1999 defined moder...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does NVIDIA's platform strategy contribute...</td>\n",
       "      <td>NVIDIA's platform strategy brings together har...</td>\n",
       "      <td>NVIDIA has a platform strategy, bringing toget...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What does NVIDIA's CUDA programming model enable?</td>\n",
       "      <td>NVIDIA's CUDA programming model opened the par...</td>\n",
       "      <td>With our introduction of the CUDA programming ...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What area did NVIDIA initially focus on before...   \n",
       "1  What are some of the recent applications of GP...   \n",
       "2  What significant invention did NVIDIA create i...   \n",
       "3  How does NVIDIA's platform strategy contribute...   \n",
       "4  What does NVIDIA's CUDA programming model enable?   \n",
       "\n",
       "                                              answer  \\\n",
       "0           NVIDIA initially focused on PC graphics.   \n",
       "1  Recent applications of GPU-powered deep learni...   \n",
       "2                   NVIDIA invented the GPU in 1999.   \n",
       "3  NVIDIA's platform strategy brings together har...   \n",
       "4  NVIDIA's CUDA programming model opened the par...   \n",
       "\n",
       "                                             context  \\\n",
       "0  Since our original focus on PC graphics, we ha...   \n",
       "1  Some of the most recent applications of GPU-po...   \n",
       "2  Our invention of the GPU in 1999 defined moder...   \n",
       "3  NVIDIA has a platform strategy, bringing toget...   \n",
       "4  With our introduction of the CUDA programming ...   \n",
       "\n",
       "                                                text  token_count  \n",
       "0  <|begin_of_text|><|start_header_id|>system<|en...           75  \n",
       "1  <|begin_of_text|><|start_header_id|>system<|en...          171  \n",
       "2  <|begin_of_text|><|start_header_id|>system<|en...           73  \n",
       "3  <|begin_of_text|><|start_header_id|>system<|en...           97  \n",
       "4  <|begin_of_text|><|start_header_id|>system<|en...           83  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7dbe266b-9e43-4868-b874-c96c4c02ee38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T15:27:00.336005Z",
     "iopub.status.busy": "2024-07-22T15:27:00.335524Z",
     "iopub.status.idle": "2024-07-22T15:27:00.350842Z",
     "shell.execute_reply": "2024-07-22T15:27:00.349621Z",
     "shell.execute_reply.started": "2024-07-22T15:27:00.335987Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.hist(df.token_count, weights=np.ones(len(df.token_count)) / len(df.token_count))\n",
    "# plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "# plt.xlabel(\"Tokens\")\n",
    "# plt.ylabel(\"Percentage\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa729957-fdce-4ab5-a01d-39e058f76be0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:54:59.856990Z",
     "iopub.status.busy": "2024-08-04T03:54:59.856573Z",
     "iopub.status.idle": "2024-08-04T03:55:00.015972Z",
     "shell.execute_reply": "2024-08-04T03:55:00.015171Z",
     "shell.execute_reply.started": "2024-08-04T03:54:59.856955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df.token_count, stat='probability', bins=30)\n",
    "\n",
    "# 设置 y 轴格式为百分比\n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "\n",
    "# 添加标签\n",
    "plt.xlabel(\"Tokens\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "\n",
    "# 显示图表\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d2eff5c0-7013-4bbd-a201-e1e18ce30116",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:55:20.260538Z",
     "iopub.status.busy": "2024-08-04T03:55:20.260160Z",
     "iopub.status.idle": "2024-08-04T03:55:20.269158Z",
     "shell.execute_reply": "2024-08-04T03:55:20.268280Z",
     "shell.execute_reply.started": "2024-08-04T03:55:20.260521Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6997, 7000, 0.9995714285714286)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.token_count < 512]), len(df), len(df[df.token_count < 512]) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a71b9721-744b-4bdf-9e7e-343d8a76c08b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T15:27:00.556460Z",
     "iopub.status.busy": "2024-07-22T15:27:00.555941Z",
     "iopub.status.idle": "2024-07-22T15:27:00.569235Z",
     "shell.execute_reply": "2024-07-22T15:27:00.568281Z",
     "shell.execute_reply.started": "2024-07-22T15:27:00.556438Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = df[df.token_count < 512]\n",
    "# df = df.sample(6000)\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ada232d2-ee1d-4549-b200-bb0f5042fa30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:55:29.060496Z",
     "iopub.status.busy": "2024-08-04T03:55:29.059837Z",
     "iopub.status.idle": "2024-08-04T03:55:29.078507Z",
     "shell.execute_reply": "2024-08-04T03:55:29.076676Z",
     "shell.execute_reply.started": "2024-08-04T03:55:29.060450Z"
    }
   },
   "outputs": [],
   "source": [
    "train, temp = train_test_split(df, test_size=0.2)\n",
    "val, test = train_test_split(temp, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f7e66712-ea1c-4e8d-b09b-af13bc959514",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:55:30.793911Z",
     "iopub.status.busy": "2024-08-04T03:55:30.792608Z",
     "iopub.status.idle": "2024-08-04T03:55:30.802089Z",
     "shell.execute_reply": "2024-08-04T03:55:30.800814Z",
     "shell.execute_reply.started": "2024-08-04T03:55:30.793866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5600, 1120, 280)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(val), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a3f2be7b-fece-4d47-accc-e19f70c05178",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:55:37.672664Z",
     "iopub.status.busy": "2024-08-04T03:55:37.672023Z",
     "iopub.status.idle": "2024-08-04T03:55:37.682922Z",
     "shell.execute_reply": "2024-08-04T03:55:37.681406Z",
     "shell.execute_reply.started": "2024-08-04T03:55:37.672618Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8, 0.16, 0.04)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train) / len(df), len(val) / len(df), len(test) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "025247a8-ad71-4fc3-bc51-c6665eba267b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:55:45.944230Z",
     "iopub.status.busy": "2024-08-04T03:55:45.943578Z",
     "iopub.status.idle": "2024-08-04T03:55:46.064594Z",
     "shell.execute_reply": "2024-08-04T03:55:46.063755Z",
     "shell.execute_reply.started": "2024-08-04T03:55:45.944182Z"
    }
   },
   "outputs": [],
   "source": [
    "train.sample(n=5000).to_json(\"./data/train.json\", orient=\"records\", lines=True)\n",
    "val.sample(n=1000).to_json(\"./data/val.json\", orient=\"records\", lines=True)\n",
    "test.sample(n=250).to_json(\"./data/test.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c855dc93-e0b7-4c5f-9c91-3fde2d159d41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:55:54.300667Z",
     "iopub.status.busy": "2024-08-04T03:55:54.300134Z",
     "iopub.status.idle": "2024-08-04T03:55:55.441809Z",
     "shell.execute_reply": "2024-08-04T03:55:55.440848Z",
     "shell.execute_reply.started": "2024-08-04T03:55:54.300641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304b4456915e4df0bb78c5fa48956ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3ecc1cca304a29ac8b5d6e3c29453b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b97cd569f9c463ba0883afccd8a647d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'context', 'text', 'token_count'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'answer', 'context', 'text', 'token_count'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer', 'context', 'text', 'token_count'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\"train\": \"./data/train.json\", \n",
    "                \"validation\": \"./data/val.json\", \n",
    "                \"test\": \"./data/test.json\"},\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893c57ea-10ff-4d5a-8057-19d04c4a6ddd",
   "metadata": {},
   "source": [
    "## sft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae58b4d1-daa9-47cf-8925-a5f03b62833e",
   "metadata": {},
   "source": [
    "### test on llama3-8b-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2b03a729-a0bd-481e-b61a-9e3179d2f5e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:56:22.601071Z",
     "iopub.status.busy": "2024-08-04T03:56:22.600041Z",
     "iopub.status.idle": "2024-08-04T03:56:22.608553Z",
     "shell.execute_reply": "2024-08-04T03:56:22.607264Z",
     "shell.execute_reply.started": "2024-08-04T03:56:22.601023Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=128,\n",
    "    return_full_text=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df72d931-7e78-4b7f-8d26-874d3c3c64fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:39:26.698682Z",
     "iopub.status.busy": "2024-08-04T04:39:26.697753Z",
     "iopub.status.idle": "2024-08-04T04:39:26.705418Z",
     "shell.execute_reply": "2024-08-04T04:39:26.704075Z",
     "shell.execute_reply.started": "2024-08-04T04:39:26.698650Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_test_prompt(data_row):\n",
    "    prompt = dedent(\n",
    "        f\"\"\"\n",
    "    {data_row[\"question\"]}\n",
    "\n",
    "    Information:\n",
    "\n",
    "    ```\n",
    "    {data_row[\"context\"]}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Use only the information to answer the question\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    return tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4cd12b41-dcdc-47bf-97cd-9d5db7add682",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:56:44.418997Z",
     "iopub.status.busy": "2024-08-04T03:56:44.417785Z",
     "iopub.status.idle": "2024-08-04T03:56:44.427545Z",
     "shell.execute_reply": "2024-08-04T03:56:44.426281Z",
     "shell.execute_reply.started": "2024-08-04T03:56:44.418952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "How does Amazon fulfill customer orders?\n",
      "\n",
      "Information:\n",
      "\n",
      "```\n",
      "Amazon fulfills customer orders using its North America and International fulfillment networks, co-sourced and outsourced arrangements in certain countries, digital delivery, and physical stores.\n",
      "```<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "row = dataset[\"test\"][0]\n",
    "prompt = create_test_prompt(row)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5143a708-5db4-48f5-b946-8120bb7a965b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:57:03.832865Z",
     "iopub.status.busy": "2024-08-04T03:57:03.832636Z",
     "iopub.status.idle": "2024-08-04T03:57:06.346889Z",
     "shell.execute_reply": "2024-08-04T03:57:06.346015Z",
     "shell.execute_reply.started": "2024-08-04T03:57:03.832851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "answer:     Amazon fulfills customer orders through a combination of North America and International fulfillment networks operated by the company, co-sourced and outsourced arrangements in some countries, digital delivery, and through its physical stores.\n",
      "prediction: According to the information, Amazon fulfills customer orders using:\n",
      "\n",
      "1. North America and International fulfillment networks\n",
      "2. Co-sourced and outsourced arrangements in certain countries\n",
      "3. Digital delivery\n",
      "4. Physical stores\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe(prompt)\n",
    "response = f\"\"\"\n",
    "answer:     {row[\"answer\"]}\n",
    "prediction: {outputs[0][\"generated_text\"]}\n",
    "\"\"\"\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6f8cb284-fe81-4a51-b99e-ebb86d7c7c40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:57:30.602055Z",
     "iopub.status.busy": "2024-08-04T03:57:30.601658Z",
     "iopub.status.idle": "2024-08-04T03:57:30.607314Z",
     "shell.execute_reply": "2024-08-04T03:57:30.606490Z",
     "shell.execute_reply.started": "2024-08-04T03:57:30.602039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Who holds the patents for the active pharmaceutical ingredients of some of the company's products?\n",
      "\n",
      "Information:\n",
      "\n",
      "```\n",
      "Patents covering certain of the active pharmaceutical ingredients (\"API\") of some of our products are held by third parties. We acquired exclusive rights to these patents in the agreements we have with these parties.\n",
      "```<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "row = dataset[\"test\"][1]\n",
    "prompt = create_test_prompt(row)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b95a2962-398c-4534-be2a-94092e49cb68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:57:32.275785Z",
     "iopub.status.busy": "2024-08-04T03:57:32.274699Z",
     "iopub.status.idle": "2024-08-04T03:57:33.174549Z",
     "shell.execute_reply": "2024-08-04T03:57:33.173695Z",
     "shell.execute_reply.started": "2024-08-04T03:57:32.275728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "answer:     The patents for the active pharmaceutical ingredients of some of the company's products are held by third parties, from whom the company has acquired exclusive rights through agreements.\n",
      "prediction: Third parties hold the patents for the active pharmaceutical ingredients of some of the company's products.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe(prompt)\n",
    "response = f\"\"\"\n",
    "answer:     {row[\"answer\"]}\n",
    "prediction: {outputs[0][\"generated_text\"]}\n",
    "\"\"\"\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9f455bef-c521-4dea-bf2b-fae4745772bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T03:58:02.074832Z",
     "iopub.status.busy": "2024-08-04T03:58:02.074631Z",
     "iopub.status.idle": "2024-08-04T04:05:04.563756Z",
     "shell.execute_reply": "2024-08-04T04:05:04.562886Z",
     "shell.execute_reply.started": "2024-08-04T03:58:02.074819Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8/250 [00:16<07:59,  1.98s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "100%|██████████| 250/250 [07:02<00:00,  1.69s/it]\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for row in tqdm(dataset[\"test\"]):\n",
    "    prompt = create_test_prompt(row)\n",
    "    outputs = pipe(prompt)\n",
    "    rows.append(\n",
    "        {\n",
    "            \"question\": row[\"question\"],\n",
    "            \"context\": row[\"context\"],\n",
    "            \"prompt\": prompt,\n",
    "            \"answer\": row[\"answer\"],\n",
    "            \"untrained_prediction\": outputs[0][\"generated_text\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "predictions_df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a448e4f-b9ef-4d6a-90b7-d74f9a3f7428",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T15:27:06.466591Z",
     "iopub.status.busy": "2024-07-22T15:27:06.466452Z",
     "iopub.status.idle": "2024-07-22T15:27:06.483710Z",
     "shell.execute_reply": "2024-07-22T15:27:06.482587Z",
     "shell.execute_reply.started": "2024-07-22T15:27:06.466580Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.arange(len(dataset[\"test\"])) // 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "50f7f648-2fbf-4feb-8ed6-68d77e9d70b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:05:41.927715Z",
     "iopub.status.busy": "2024-08-04T04:05:41.927100Z",
     "iopub.status.idle": "2024-08-04T04:05:41.946671Z",
     "shell.execute_reply": "2024-08-04T04:05:41.945344Z",
     "shell.execute_reply.started": "2024-08-04T04:05:41.927671Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "      <th>untrained_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does Amazon fulfill customer orders?</td>\n",
       "      <td>Amazon fulfills customer orders using its Nort...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>Amazon fulfills customer orders through a comb...</td>\n",
       "      <td>According to the information, Amazon fulfills ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who holds the patents for the active pharmaceu...</td>\n",
       "      <td>Patents covering certain of the active pharmac...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>The patents for the active pharmaceutical ingr...</td>\n",
       "      <td>Third parties hold the patents for the active ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does JPMorgan Chase ensure that its compen...</td>\n",
       "      <td>Compensation and benefits: JPMorgan Chase’s co...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>JPMorgan Chase’s compensation philosophy inclu...</td>\n",
       "      <td>According to the information, JPMorgan Chase e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What will happen if the proposed revisions on ...</td>\n",
       "      <td>In 2016, the federal banking regulators, the S...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>If the proposed revisions on incentive-based p...</td>\n",
       "      <td>If the proposed revisions on incentive-based p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the typical higher sales quarters for...</td>\n",
       "      <td>Sales are typically higher during the third an...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|en...</td>\n",
       "      <td>The third and fourth quarters of the year.</td>\n",
       "      <td>According to the information, the typical high...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0           How does Amazon fulfill customer orders?   \n",
       "1  Who holds the patents for the active pharmaceu...   \n",
       "2  How does JPMorgan Chase ensure that its compen...   \n",
       "3  What will happen if the proposed revisions on ...   \n",
       "4  What are the typical higher sales quarters for...   \n",
       "\n",
       "                                             context  \\\n",
       "0  Amazon fulfills customer orders using its Nort...   \n",
       "1  Patents covering certain of the active pharmac...   \n",
       "2  Compensation and benefits: JPMorgan Chase’s co...   \n",
       "3  In 2016, the federal banking regulators, the S...   \n",
       "4  Sales are typically higher during the third an...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "1  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "2  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "3  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "4  <|begin_of_text|><|start_header_id|>system<|en...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Amazon fulfills customer orders through a comb...   \n",
       "1  The patents for the active pharmaceutical ingr...   \n",
       "2  JPMorgan Chase’s compensation philosophy inclu...   \n",
       "3  If the proposed revisions on incentive-based p...   \n",
       "4         The third and fourth quarters of the year.   \n",
       "\n",
       "                                untrained_prediction  \n",
       "0  According to the information, Amazon fulfills ...  \n",
       "1  Third parties hold the patents for the active ...  \n",
       "2  According to the information, JPMorgan Chase e...  \n",
       "3  If the proposed revisions on incentive-based p...  \n",
       "4  According to the information, the typical high...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aef6216-ee05-469e-94a2-60dacae5e7dc",
   "metadata": {},
   "source": [
    "### Train on Completions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3cf458-6cea-4c97-8302-c5ffa67c162b",
   "metadata": {},
   "source": [
    "- collate_fn\n",
    "    - DataCollatorForCompletionOnlyLM\n",
    "        - data collator used for completion tasks. It ensures that all the tokens of the labels are set to an 'ignore_index'\n",
    "    when they do not come from the assistant. This ensure that the loss is only\n",
    "    calculated on the completion made by the assistant.\n",
    "    - 实例化的 collator 作为 SFTrainer 的 data_collator 的参数；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "371f3df3-11a2-4b35-88f3-c441c6df9265",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:05:45.717143Z",
     "iopub.status.busy": "2024-08-04T04:05:45.716545Z",
     "iopub.status.idle": "2024-08-04T04:05:45.726252Z",
     "shell.execute_reply": "2024-08-04T04:05:45.724871Z",
     "shell.execute_reply.started": "2024-08-04T04:05:45.717099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Who is the Chief Financial Officer and since when?\n",
      "\n",
      "Information:\n",
      "\n",
      "```\n",
      "Richard A. Galanti | Executive Vice President and Chief Financial Officer. Mr. Galanti has been a director since January 1995.\n",
      "```<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Richard A. Galanti is the Executive Vice President and Chief Financial Officer, and he has been in this role since 1993.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "examples = [dataset[\"train\"][0][\"text\"]]\n",
    "print(examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "93337f0a-a567-43c7-bd0e-c571ea316e6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:07:43.139585Z",
     "iopub.status.busy": "2024-08-04T04:07:43.138423Z",
     "iopub.status.idle": "2024-08-04T04:07:43.146169Z",
     "shell.execute_reply": "2024-08-04T04:07:43.144813Z",
     "shell.execute_reply.started": "2024-08-04T04:07:43.139534Z"
    }
   },
   "outputs": [],
   "source": [
    "response_template = \"<|end_header_id|>\"\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)\n",
    "# collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bc76b73f-ada4-496c-9c55-3735727cc90f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:07:46.420840Z",
     "iopub.status.busy": "2024-08-04T04:07:46.419334Z",
     "iopub.status.idle": "2024-08-04T04:07:46.427918Z",
     "shell.execute_reply": "2024-08-04T04:07:46.426458Z",
     "shell.execute_reply.started": "2024-08-04T04:07:46.420795Z"
    }
   },
   "outputs": [],
   "source": [
    "encodings = [tokenizer(e) for e in examples]\n",
    "dataloader = DataLoader(encodings, collate_fn=collator, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6789d4c2-9124-4fac-9242-8f05382e0f73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:07:53.030493Z",
     "iopub.status.busy": "2024-08-04T04:07:53.029192Z",
     "iopub.status.idle": "2024-08-04T04:07:53.040386Z",
     "shell.execute_reply": "2024-08-04T04:07:53.039139Z",
     "shell.execute_reply.started": "2024-08-04T04:07:53.030446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(dataloader))\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a79ec3ab-8b2c-4614-844c-addb6abd90b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T15:27:06.532418Z",
     "iopub.status.busy": "2024-07-22T15:27:06.531862Z",
     "iopub.status.idle": "2024-07-22T15:27:06.538744Z",
     "shell.execute_reply": "2024-07-22T15:27:06.537805Z",
     "shell.execute_reply.started": "2024-07-22T15:27:06.532398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[128000, 128006,   9125, 128007,    271,  10464,   1193,    279,   2038,\n",
       "            311,   4320,    279,   3488, 128009, 128006,    882, 128007,    271,\n",
       "          15546,    374,    279,  14681,  17961,  20148,    323,   2533,    994,\n",
       "           1980,  15218,   1473,  14196,   4077,  42315,    362,     13,  10845,\n",
       "          15719,    765,  18362,  23270,   4900,    323,  14681,  17961,  20148,\n",
       "             13,   4491,     13,  10845,  15719,    706,   1027,    264,   7690,\n",
       "           2533,   6186,    220,   2550,     20,    627,  74694, 128009, 128006,\n",
       "          78191, 128007,    271,  42315,    362,     13,  10845,  15719,    374,\n",
       "            279,  18362,  23270,   4900,    323,  14681,  17961,  20148,     11,\n",
       "            323,    568,    706,   1027,    304,    420,   3560,   2533,    220,\n",
       "           2550,     18,     13, 128009]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d1f876bc-6a6c-41cb-ac40-720c3b51bc59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:08:03.853337Z",
     "iopub.status.busy": "2024-08-04T04:08:03.852093Z",
     "iopub.status.idle": "2024-08-04T04:08:03.862758Z",
     "shell.execute_reply": "2024-08-04T04:08:03.861869Z",
     "shell.execute_reply.started": "2024-08-04T04:08:03.853289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,    271,  42315,    362,     13,  10845,  15719,    374,\n",
       "            279,  18362,  23270,   4900,    323,  14681,  17961,  20148,     11,\n",
       "            323,    568,    706,   1027,    304,    420,   3560,   2533,    220,\n",
       "           2550,     18,     13, 128009]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f0c72e76-3a42-4295-a471-7357af8c3edc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:08:36.255951Z",
     "iopub.status.busy": "2024-08-04T04:08:36.255206Z",
     "iopub.status.idle": "2024-08-04T04:08:36.265067Z",
     "shell.execute_reply": "2024-08-04T04:08:36.263808Z",
     "shell.execute_reply.started": "2024-08-04T04:08:36.255905Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nRichard A. Galanti is the Executive Vice President and Chief Financial Officer, and he has been in this role since 1993.<|eot_id|>'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([271,  42315,    362,     13,  10845,  15719,    374,\n",
    "            279,  18362,  23270,   4900,    323,  14681,  17961,  20148,     11,\n",
    "            323,    568,    706,   1027,    304,    420,   3560,   2533,    220,\n",
    "           2550,     18,     13, 128009])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b963fa2a-db32-445b-a230-d99fc3585ea9",
   "metadata": {},
   "source": [
    "### lora setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6aa06fb1-eabb-48f5-b8b7-e365ec25f510",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:08:46.131084Z",
     "iopub.status.busy": "2024-08-04T04:08:46.129861Z",
     "iopub.status.idle": "2024-08-04T04:08:46.142480Z",
     "shell.execute_reply": "2024-08-04T04:08:46.141205Z",
     "shell.execute_reply.started": "2024-08-04T04:08:46.131038Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128264, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128264, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "486f1889-d34d-41b3-ade6-11eac09c6c78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:09:21.061645Z",
     "iopub.status.busy": "2024-08-04T04:09:21.060489Z",
     "iopub.status.idle": "2024-08-04T04:09:21.998231Z",
     "shell.execute_reply": "2024-08-04T04:09:21.997697Z",
     "shell.execute_reply.started": "2024-08-04T04:09:21.061629Z"
    }
   },
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "        \"self_attn.q_proj\",\n",
    "        \"self_attn.k_proj\",\n",
    "        \"self_attn.v_proj\",\n",
    "        \"self_attn.o_proj\",\n",
    "        \"mlp.gate_proj\",\n",
    "        \"mlp.up_proj\",\n",
    "        \"mlp.down_proj\",\n",
    "    ],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    ")\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ca025777-4626-4459-921c-a95dfe011d6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:09:22.322818Z",
     "iopub.status.busy": "2024-08-04T04:09:22.322586Z",
     "iopub.status.idle": "2024-08-04T04:09:22.332778Z",
     "shell.execute_reply": "2024-08-04T04:09:22.331943Z",
     "shell.execute_reply.started": "2024-08-04T04:09:22.322803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 83,886,080 || all params: 8,114,212,864 || trainable%: 1.0338166055782685\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a3875d-8d85-4251-82bb-36fa55a20f3f",
   "metadata": {},
   "source": [
    "### sft train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0a99ce81-ed11-4f7a-9dc3-70b4dbded16c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:09:50.397501Z",
     "iopub.status.busy": "2024-08-04T04:09:50.397287Z",
     "iopub.status.idle": "2024-08-04T04:09:50.404366Z",
     "shell.execute_reply": "2024-08-04T04:09:50.403000Z",
     "shell.execute_reply.started": "2024-08-04T04:09:50.397487Z"
    }
   },
   "outputs": [],
   "source": [
    "output_dir = \"experiments\"\n",
    "\n",
    "# # ssh -L 6006:localhost:6006 user@remote_server\n",
    "# # localhost:6006\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir \"experiments/runs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "597f6dd4-3515-4651-884a-7a7bb5933f29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:10:23.290344Z",
     "iopub.status.busy": "2024-08-04T04:10:23.289020Z",
     "iopub.status.idle": "2024-08-04T04:10:23.295291Z",
     "shell.execute_reply": "2024-08-04T04:10:23.294486Z",
     "shell.execute_reply.started": "2024-08-04T04:10:23.290297Z"
    }
   },
   "outputs": [],
   "source": [
    "# dual 4090s\n",
    "# accelerate config 会自动地配置这两个环境变量 \n",
    "os.environ[\"NCCL_P2P_DISABLE\"] = \"1\"\n",
    "os.environ[\"NCCL_IB_DISABLE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7b25050a-42fa-4b91-baf5-539aa3c6bf7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:10:25.058907Z",
     "iopub.status.busy": "2024-08-04T04:10:25.058072Z",
     "iopub.status.idle": "2024-08-04T04:10:25.066111Z",
     "shell.execute_reply": "2024-08-04T04:10:25.065325Z",
     "shell.execute_reply.started": "2024-08-04T04:10:25.058859Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'context', 'text', 'token_count'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a4aae8be-d911-4558-8987-4fb6a162731f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:10:27.200664Z",
     "iopub.status.busy": "2024-08-04T04:10:27.200051Z",
     "iopub.status.idle": "2024-08-04T04:10:27.208738Z",
     "shell.execute_reply": "2024-08-04T04:10:27.207456Z",
     "shell.execute_reply.started": "2024-08-04T04:10:27.200621Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156.25"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# global_step=156\n",
    "5000/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "88ace1fb-5ce4-48bf-a866-1a1b5d71be04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T15:27:08.699499Z",
     "iopub.status.busy": "2024-07-22T15:27:08.698589Z",
     "iopub.status.idle": "2024-07-22T15:27:08.785582Z",
     "shell.execute_reply": "2024-07-22T15:27:08.784381Z",
     "shell.execute_reply.started": "2024-07-22T15:27:08.699457Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31.25,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eval_steps=0.2,\n",
    "len(dataset['train']) / (8*4) * .2, len(dataset['validation']) / 8,\n",
    "# save_steps=0.2, save_total_limit=2,\n",
    "# checkpoint-32-64-96-128-256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "021ec813-f22f-455e-ac4c-319c058e53a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:11:54.197283Z",
     "iopub.status.busy": "2024-08-04T04:11:54.197043Z",
     "iopub.status.idle": "2024-08-04T04:11:54.200858Z",
     "shell.execute_reply": "2024-08-04T04:11:54.200369Z",
     "shell.execute_reply.started": "2024-08-04T04:11:54.197263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Who is the Chief Financial Officer and since when?\n",
      "\n",
      "Information:\n",
      "\n",
      "```\n",
      "Richard A. Galanti | Executive Vice President and Chief Financial Officer. Mr. Galanti has been a director since January 1995.\n",
      "```<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Richard A. Galanti is the Executive Vice President and Chief Financial Officer, and he has been in this role since 1993.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0fbabb35-c10f-4c24-af80-e5b8222e0f4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:15:05.566600Z",
     "iopub.status.busy": "2024-08-04T04:15:05.566393Z",
     "iopub.status.idle": "2024-08-04T04:15:07.948386Z",
     "shell.execute_reply": "2024-08-04T04:15:07.947552Z",
     "shell.execute_reply.started": "2024-08-04T04:15:05.566587Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93c7903e3fe24dbcae66d973ff348446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sft_config = SFTConfig(\n",
    "    output_dir=output_dir,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=512,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=0.2,\n",
    "    save_steps=0.2,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=10,\n",
    "    learning_rate=1e-4,\n",
    "    bf16=True,  # or fp16=True,\n",
    "    save_strategy=\"steps\",\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"wandb\",\n",
    "    save_safetensors=True,\n",
    "    dataset_kwargs={\n",
    "        \"add_special_tokens\": False,  # We template with special tokens\n",
    "        \"append_concat_token\": False,  # No need to add additional separator token\n",
    "    },\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=sft_config,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "42844415-b683-42e6-9c42-20032d500067",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:15:18.949997Z",
     "iopub.status.busy": "2024-08-04T04:15:18.949789Z",
     "iopub.status.idle": "2024-08-04T04:30:25.601588Z",
     "shell.execute_reply": "2024-08-04T04:30:25.600807Z",
     "shell.execute_reply.started": "2024-08-04T04:15:18.949984Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlanchunhui\u001b[0m (\u001b[33mloveresearch\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/whaow/workspaces/llms_tuning/tutorials/finetune/examples/wandb/run-20240804_121521-dpspiivr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/loveresearch/huggingface/runs/dpspiivr' target=\"_blank\">experiments</a></strong> to <a href='https://wandb.ai/loveresearch/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/loveresearch/huggingface' target=\"_blank\">https://wandb.ai/loveresearch/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/loveresearch/huggingface/runs/dpspiivr' target=\"_blank\">https://wandb.ai/loveresearch/huggingface/runs/dpspiivr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156' max='156' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156/156 14:47, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.513800</td>\n",
       "      <td>0.513654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.445100</td>\n",
       "      <td>0.499149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.431900</td>\n",
       "      <td>0.492684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.473000</td>\n",
       "      <td>0.486104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-66af0127-3bf0249c2e619d1770995a2e;4d3fdc37-a7c2-4bdb-8bd1-743cc2d45904)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json.\n",
      "Access to model meta-llama/Meta-Llama-3-8B-Instruct is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in meta-llama/Meta-Llama-3-8B-Instruct.\n",
      "  warnings.warn(\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in meta-llama/Meta-Llama-3-8B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-66af01e5-42f825265a6038a1762b044a;44d71838-6244-4cc2-9ec4-75521184eece)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json.\n",
      "Access to model meta-llama/Meta-Llama-3-8B-Instruct is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in meta-llama/Meta-Llama-3-8B-Instruct.\n",
      "  warnings.warn(\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in meta-llama/Meta-Llama-3-8B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-66af02a5-098a3d39735b1a49705c9246;e4a47e62-55e4-4d13-841b-d1e32017894e)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json.\n",
      "Access to model meta-llama/Meta-Llama-3-8B-Instruct is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in meta-llama/Meta-Llama-3-8B-Instruct.\n",
      "  warnings.warn(\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in meta-llama/Meta-Llama-3-8B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-66af0367-58bf769754c8bbe2268889d7;371aaf39-42b0-4602-8524-14198dbaddda)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json.\n",
      "Access to model meta-llama/Meta-Llama-3-8B-Instruct is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in meta-llama/Meta-Llama-3-8B-Instruct.\n",
      "  warnings.warn(\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in meta-llama/Meta-Llama-3-8B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-66af03e0-348995ce24b602627338c8b0;c4ef8b17-eaf0-4f07-895a-7312fc525292)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json.\n",
      "Access to model meta-llama/Meta-Llama-3-8B-Instruct is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in meta-llama/Meta-Llama-3-8B-Instruct.\n",
      "  warnings.warn(\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in meta-llama/Meta-Llama-3-8B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=156, training_loss=0.48811453122359055, metrics={'train_runtime': 906.2911, 'train_samples_per_second': 5.517, 'train_steps_per_second': 0.172, 'total_flos': 4.268560560979968e+16, 'train_loss': 0.48811453122359055, 'epoch': 0.9984})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc23a27-22c8-4e07-85b8-9da95eb4f162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !accelerate launch --mixed_precision bf16 training_scripts.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f3ae2ed1-1494-43ad-bb72-5657556a29e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:30:35.367294Z",
     "iopub.status.busy": "2024-08-04T04:30:35.367077Z",
     "iopub.status.idle": "2024-08-04T04:30:35.372963Z",
     "shell.execute_reply": "2024-08-04T04:30:35.372097Z",
     "shell.execute_reply.started": "2024-08-04T04:30:35.367280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Llama-3-8B-Instruct-Finance-RAG'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9cbbdd5f-8755-4eb1-a022-8efa0be77c0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:30:36.977448Z",
     "iopub.status.busy": "2024-08-04T04:30:36.976244Z",
     "iopub.status.idle": "2024-08-04T04:30:38.069719Z",
     "shell.execute_reply": "2024-08-04T04:30:38.069029Z",
     "shell.execute_reply.started": "2024-08-04T04:30:36.977406Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whaow/anaconda3/lib/python3.10/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-66af03ed-5b6ccb3f2075d03a3cbb9d67;464545b6-c6aa-4ff7-b671-0e8a2bb35fbb)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json.\n",
      "Access to model meta-llama/Meta-Llama-3-8B-Instruct is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in meta-llama/Meta-Llama-3-8B-Instruct.\n",
      "  warnings.warn(\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in meta-llama/Meta-Llama-3-8B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(new_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c68bb9-a577-4349-a096-e7dd26f08c01",
   "metadata": {},
   "source": [
    "## load sft trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edeeb5f7-5550-4035-8f97-c2e7c1045329",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:38:19.061357Z",
     "iopub.status.busy": "2024-08-04T04:38:19.060971Z",
     "iopub.status.idle": "2024-08-04T04:38:25.828709Z",
     "shell.execute_reply": "2024-08-04T04:38:25.827755Z",
     "shell.execute_reply.started": "2024-08-04T04:38:19.061336Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83ee5457f7749d3a14689d44f107c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We've detected an older driver with an RTX 4000 series GPU. These drivers have issues with P2P. This can affect the multi-gpu inference when using accelerate device_map.Please make sure to update your driver to the latest version which resolves this.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(new_model)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=8)\n",
    "model = PeftModel.from_pretrained(model, new_model)\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd84884-1ad5-4f49-8e38-a5ebbc46164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.push_to_hub(new_model, tokenizer=tokenizer, max_shard_size=\"5GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343d44cb-1ecc-44af-abdf-292f1b0aa14d",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a042766-9d4c-401c-a361-5967803fd6a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:38:34.325270Z",
     "iopub.status.busy": "2024-08-04T04:38:34.324998Z",
     "iopub.status.idle": "2024-08-04T04:38:35.307759Z",
     "shell.execute_reply": "2024-08-04T04:38:35.307050Z",
     "shell.execute_reply.started": "2024-08-04T04:38:34.325251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'context', 'text', 'token_count'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'answer', 'context', 'text', 'token_count'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer', 'context', 'text', 'token_count'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\"train\": \"./data/train.json\", \n",
    "                \"validation\": \"./data/val.json\", \n",
    "                \"test\": \"./data/test.json\"},\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ed612d7-0968-4b9d-a662-67a10573ef76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:38:42.315864Z",
     "iopub.status.busy": "2024-08-04T04:38:42.314635Z",
     "iopub.status.idle": "2024-08-04T04:38:49.419591Z",
     "shell.execute_reply": "2024-08-04T04:38:49.418931Z",
     "shell.execute_reply.started": "2024-08-04T04:38:42.315807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0928d57e0624273888cf1f8b6f0cf94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We've detected an older driver with an RTX 4000 series GPU. These drivers have issues with P2P. This can affect the multi-gpu inference when using accelerate device_map.Please make sure to update your driver to the latest version which resolves this.\n"
     ]
    }
   ],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('./Llama-3-8B-Instruct-Finance-RAG', use_fast=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    './Llama-3-8B-Instruct-Finance-RAG', quantization_config=quantization_config, device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea1c4bd5-6a57-47d5-9585-de4db942eb09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:39:11.118808Z",
     "iopub.status.busy": "2024-08-04T04:39:11.118526Z",
     "iopub.status.idle": "2024-08-04T04:39:11.124022Z",
     "shell.execute_reply": "2024-08-04T04:39:11.123009Z",
     "shell.execute_reply.started": "2024-08-04T04:39:11.118790Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=128,\n",
    "    return_full_text=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe6648e7-260f-44f1-a3cb-95edb59fd81e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T04:40:17.389966Z",
     "iopub.status.busy": "2024-08-04T04:40:17.389004Z",
     "iopub.status.idle": "2024-08-04T04:40:17.414610Z",
     "shell.execute_reply": "2024-08-04T04:40:17.413186Z",
     "shell.execute_reply.started": "2024-08-04T04:40:17.389917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "How does Amazon fulfill customer orders?\n",
      "\n",
      "Information:\n",
      "\n",
      "```\n",
      "Amazon fulfills customer orders using its North America and International fulfillment networks, co-sourced and outsourced arrangements in certain countries, digital delivery, and physical stores.\n",
      "```<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "row = dataset[\"test\"][0]\n",
    "prompt = create_test_prompt(row)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c57627c-49cf-4ecd-bd18-ad5ecb494917",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T08:41:32.162414Z",
     "iopub.status.busy": "2024-08-04T08:41:32.161791Z",
     "iopub.status.idle": "2024-08-04T08:41:36.251280Z",
     "shell.execute_reply": "2024-08-04T08:41:36.250304Z",
     "shell.execute_reply.started": "2024-08-04T08:41:32.162368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "answer:     Amazon fulfills customer orders through a combination of North America and International fulfillment networks operated by the company, co-sourced and outsourced arrangements in some countries, digital delivery, and through its physical stores.\n",
      "prediction: Amazon fulfills customer orders using its North America and International fulfillment networks, co-sourced and outsourced arrangements in certain countries, digital delivery, and physical stores.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe(prompt)\n",
    "response = f\"\"\"\n",
    "answer:     {row[\"answer\"]}\n",
    "prediction: {outputs[0][\"generated_text\"]}\n",
    "\"\"\"\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158eb1e2-1ce8-439c-8068-4ca32bc1a70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for row in tqdm(dataset[\"test\"]):\n",
    "    outputs = pipe(create_test_prompt(row))\n",
    "    predictions.append(outputs[0][\"generated_text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
