{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72d2a0dd-05c1-493c-8be7-b1294af2099b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T11:58:07.188478Z",
     "iopub.status.busy": "2024-07-30T11:58:07.188026Z",
     "iopub.status.idle": "2024-07-30T11:58:07.194219Z",
     "shell.execute_reply": "2024-07-30T11:58:07.192436Z",
     "shell.execute_reply.started": "2024-07-30T11:58:07.188457Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['NCCL_P2P_DISABLE'] = '1'\n",
    "os.environ['NCCL_IB_DISABLE'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c2833b9-6b41-49c8-972a-e061149c6e86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T11:56:09.725546Z",
     "iopub.status.busy": "2024-07-30T11:56:09.724127Z",
     "iopub.status.idle": "2024-07-30T11:56:20.753858Z",
     "shell.execute_reply": "2024-07-30T11:56:20.752660Z",
     "shell.execute_reply.started": "2024-07-30T11:56:09.725497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-30 19:56:19,465] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda5d248-6b99-4947-a639-1ce5c2f0f8af",
   "metadata": {},
   "source": [
    "### basics & overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40fef4b-342b-43da-bded-03277087972c",
   "metadata": {},
   "source": [
    "- model_kwargs => model：实例化构造 model\n",
    "- TraingArguments\n",
    "    - @dataclass\n",
    "- SFTConfig: `class SFTConfig(TrainingArguments)`\n",
    "    - @dataclass\n",
    "    - 继承自 TrainingArguments，又新增了一些参数\n",
    "\n",
    "```\n",
    "trainer = SFTTrainer(\n",
    "    ...\n",
    "    args=sft_config\n",
    "    ...\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad86abbe-f689-40d0-bdad-19584f21e64c",
   "metadata": {},
   "source": [
    "- 注意一些参数兼容性\n",
    "    - dataset_num_proc (SFTConfig)\n",
    "    - The number of workers to use to tokenize the data. Only used when `packing=False`. Defaults to None.\n",
    "- use_cache=False, # set to False as we're going to use gradient checkpointing\n",
    "    - model_kwargs\n",
    "    - Gradient checkpointing requires recomputing activations during the backward pass, while caching aims to save those activations to avoid recomputation. These two approaches are fundamentally at odds [1].\n",
    "    - Gradient checkpointing forces multiple forward passes to recompute activations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f039d9-806c-41ab-bc01-e8087b5d3db3",
   "metadata": {},
   "source": [
    "```\n",
    "model.config.use_cache = False  # During training with checkpointing\n",
    "# ... training loop ...\n",
    "model.config.use_cache = True   # Re-enable for inference\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee4b3f1-61d6-45d9-bd89-e31c97019df7",
   "metadata": {},
   "source": [
    "- You can use the `DataCollatorForCompletionOnlyLM` to train your model on the generated prompts only.\n",
    "    - Note that this works only in the case when packing=False. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d72bd45-7664-47d3-85df-ee0ec1c25b72",
   "metadata": {},
   "source": [
    "### wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db5e4db-b892-4dbf-bffc-e27936b24865",
   "metadata": {},
   "source": [
    "```\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "```\n",
    "\n",
    "- 关闭 wandb 服务\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63830ffe-764e-4b2a-9c61-d0d51fc43688",
   "metadata": {},
   "source": [
    "### model kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f85e9b-2ac6-45a5-8f06-99d3f4453161",
   "metadata": {},
   "source": [
    "```\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\", \n",
    "    bnb_4bit_use_double_quant=True, \n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "device_map = {\"\": torch.cuda.current_device()} if torch.cuda.is_available() else None\n",
    "\n",
    "model_kwargs = dict(\n",
    "    attn_implementation=\"flash_attention_2\", \n",
    "    torch_dtype=\"auto\",\n",
    "    use_cache=False, # set to False as we're going to use gradient checkpointing\n",
    "    device_map=device_map,\n",
    "    quantization_config=quantization_config,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c82b306-6e03-4454-be41-b54b4071bfdb",
   "metadata": {},
   "source": [
    "### TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f602fb56-9949-4613-b79f-53b6c821ca0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T11:59:33.250551Z",
     "iopub.status.busy": "2024-07-30T11:59:33.249937Z",
     "iopub.status.idle": "2024-07-30T11:59:33.313587Z",
     "shell.execute_reply": "2024-07-30T11:59:33.311819Z",
     "shell.execute_reply.started": "2024-07-30T11:59:33.250506Z"
    }
   },
   "outputs": [],
   "source": [
    "# experimental settings\n",
    "training_arguments = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        gradient_accumulation_steps=2,\n",
    "        optim=\"adamw_8bit\",  # paged_adamw_8bit, adam 非常吃内存\n",
    "        logging_steps=50,\n",
    "        learning_rate=1e-4,  # 1e-6 ~ 1e-3: 1e-3, 5e-4, 1e-4\n",
    "        eval_strategy=\"steps\",\n",
    "        do_eval=True,\n",
    "        eval_steps=50,\n",
    "        save_steps=100,\n",
    "        fp16= not torch.cuda.is_bf16_supported(),\n",
    "        bf16= torch.cuda.is_bf16_supported(),\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.0,\n",
    "        warmup_ratio=0.1,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        gradient_checkpointing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f623bb-192e-41f6-ba61-f5629c8b7981",
   "metadata": {},
   "source": [
    "- eval_strategy: `no, steps, epoch`\n",
    "- lr schedule type, predefined plan，避免局部极小值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71648fc-2b80-4014-81d7-3bf8ce17e9ba",
   "metadata": {},
   "source": [
    "### SFTConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01af0543-782e-43c4-b960-251b540409f6",
   "metadata": {},
   "source": [
    "- `class SFTConfig(TrainingArguments):`\n",
    "    - 继承了 TrainingArguments 类，\n",
    "        - `num_train_epochs`: default 3\n",
    "        - `per_device_train_batch_size`: default 8\n",
    "        - `per_device_eval_batch_size`: default 8\n",
    "        - `gradient_accumulation_steps`: default 1\n",
    "        - `dataloader_drop_last`: default false\n",
    "        - `report_to`:\n",
    "            - none\n",
    "            - tensorboard\n",
    "            - wandb\n",
    "- `dataset_text_field`: 跟 dataset 的成员对齐\n",
    "- `max_seq_length`\n",
    "- `output_dir='/tmp'`\n",
    "- **packing=True**,\n",
    "    - example packing, where multiple short examples are packed in the same input sequence to increase training efficiency. \n",
    "    - `# allows multiple shorter sequences to be packed into a single training example, maximizing the use of the model's context window.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e70f60c-fa65-481e-9380-bc800bc978a9",
   "metadata": {},
   "source": [
    "#### packing vs. non-packing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cd6933-8673-49d8-9336-503c979fefe3",
   "metadata": {},
   "source": [
    "- packing => ConstantLengthDataset\n",
    "    - max_seq_length\n",
    "    ```\n",
    "    constant_length_iterator = ConstantLengthDataset(\n",
    "        tokenizer,\n",
    "        dataset,\n",
    "        dataset_text_field=dataset_text_field,\n",
    "        formatting_func=formatting_func,\n",
    "        seq_length=max_seq_length,\n",
    "        infinite=False,\n",
    "        num_of_sequences=num_of_sequences,\n",
    "        chars_per_token=chars_per_token,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        append_concat_token=append_concat_token,\n",
    "        add_special_tokens=add_special_tokens,\n",
    "    )\n",
    "    ```\n",
    "- non-packing\n",
    "    ```\n",
    "    tokenized_dataset = dataset.map(\n",
    "            tokenize,\n",
    "            batched=True,\n",
    "            remove_columns=dataset.column_names if remove_unused_columns else None,\n",
    "            num_proc=self.dataset_num_proc,\n",
    "            batch_size=self.dataset_batch_size,\n",
    "        )\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d184560-e86c-428f-911a-52621813923f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T03:07:05.787563Z",
     "iopub.status.busy": "2024-07-28T03:07:05.786145Z",
     "iopub.status.idle": "2024-07-28T03:07:20.085390Z",
     "shell.execute_reply": "2024-07-28T03:07:20.083636Z",
     "shell.execute_reply.started": "2024-07-28T03:07:05.787510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c934177576da45cab4d2302ff66ae291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f41eb1cad8947329dafa3880d0847cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4226710866486aa99119410ad31260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb = load_dataset('imdb', split='train')\n",
    "imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a165680-c1e6-4416-ac70-88011665ca20",
   "metadata": {},
   "source": [
    "```\n",
    "sft_config = SFTConfig(\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=512,\n",
    "    output_dir=\"/tmp\",\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4becad-14d2-4c5a-8450-e70343ace63a",
   "metadata": {},
   "source": [
    "### training steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e996776-7759-4d02-bff8-814724a66bae",
   "metadata": {},
   "source": [
    "```\n",
    "# 20022\n",
    "dataset = load_dataset(\"lucasmccabe-lmi/CodeAlpaca-20k\", split=\"train\")\n",
    "\n",
    "args = SFTConfig(output_dir=\"/tmp\", \n",
    "                 max_seq_length=512, \n",
    "                 num_train_epochs=2, \n",
    "                 per_device_train_batch_size=4, \n",
    "                 gradient_accumulation_steps=4,\n",
    "                 gradient_checkpointing=True,\n",
    "                 )\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    train_dataset=dataset,\n",
    "    args=args,\n",
    "    formatting_func=formatting_prompts_func,\n",
    "    data_collator=collator,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9b429a-4d75-4e3d-8db5-5061834848c9",
   "metadata": {},
   "source": [
    "- training_epochs * len(dataset) / (_train_batch_size * args.gradient_accumulation_steps * args.world_size)\n",
    "    - `20022 * 2 / (4*4*2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f086a2a-a15e-4dee-9000-7e7241122cc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T05:16:46.942858Z",
     "iopub.status.busy": "2024-07-28T05:16:46.941246Z",
     "iopub.status.idle": "2024-07-28T05:16:46.950277Z",
     "shell.execute_reply": "2024-07-28T05:16:46.949041Z",
     "shell.execute_reply.started": "2024-07-28T05:16:46.942806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1251.375"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20022 * 2 / (4*4*2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
